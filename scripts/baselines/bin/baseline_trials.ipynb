{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhikanikam/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Code for establishing baseline scores instructor intervention predictions for a portion of the MOOC \n",
    "annotation corpus. This code predicts only results for Task 2.1 \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "Google n gram corpus for idf, --- http://trimc-nlp.blogspot.sg/2013/04/tfidf-with-google-n-grams-and-pos-tags.html\n",
    "https://news.ycombinator.com/item?id=698991\n",
    "\n",
    "lexicon for first names -- https://stackoverflow.com/questions/20290870/improving-the-extraction-of-human-names-with-nltk?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n",
    "https://nlp.stanford.edu/software/CRF-NER.shtml\n",
    "https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "\n",
    "\n",
    "add no of posts, comments, no. of posts_comments, no. of sentences, avg. no of sentences per post/comment, \n",
    "avg. no of words per post to features\n",
    "thread length ftrs -- no. posts+comments, posts, comments, no of sentences in thread and no. of words (after removing stop words)\n",
    "\n",
    "from svm classifer -- output weights of features--word, tfidf weight, svm weight. After classification we can see top 10 weights\n",
    "add more data\n",
    "fix cross validation\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "import operator\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "df = pd.read_csv('../data/21total_preprocessed.csv')\n",
    "print(tensorflow.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              Title  \\\n",
      "0           0                        Put the Essays in an e-book   \n",
      "1           1  Need help with 'common sense' understanding of...   \n",
      "2           2                            Quiz deadline confusion   \n",
      "3           3                   HELP--Anyone with good internet?   \n",
      "4           4  It is not my fault that your site can not with...   \n",
      "\n",
      "          Course  Categories  \\\n",
      "0  amnhearth-002    resolves   \n",
      "1  amnhearth-002  elaborates   \n",
      "2  amnhearth-002    resolves   \n",
      "3  amnhearth-002    resolves   \n",
      "4  amnhearth-002    resolves   \n",
      "\n",
      "                                           Post_text Comment_text  Post_count  \\\n",
      "0  During the recent Human Evolution: Past and Pr...          NaN           1   \n",
      "1                                                NaN          NaN           0   \n",
      "2  Today I discovered this course and decided to ...          NaN           3   \n",
      "3  Hi, I have spent the last three hours trying t...          NaN           5   \n",
      "4  Hi - I repeat my request. It is not the short ...          NaN           1   \n",
      "\n",
      "   Comment_count  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "0    227\n",
      "1    110\n",
      "2     49\n",
      "3     25\n",
      "Name: Categories, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preparing and printing the data\n",
    "'''\n",
    "\n",
    "del df['Task2.1']\n",
    "print(df.head())\n",
    "df2 = pd.read_csv('../data/nustotal_preprocessed.csv')\n",
    "df = df.append(df2)\n",
    "\n",
    "df['Categories'] = df['Categories'].factorize()[0]\n",
    "#print((df.head(10)))\n",
    "print(df['Categories'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Removing Names\n",
    "\n",
    "def extract_entities(text):\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'node'):\n",
    "                print(chunk.node, ' '.join(c[0] for c in chunk.leaves()))\n",
    "\n",
    "# from nltk.tag import StanfordNERTagger\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# st = StanfordNERTagger('/usr/share/stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "# \t\t\t\t\t   '/usr/share/stanford-ner/stanford-ner.jar',\n",
    "# \t\t\t\t\t   encoding='utf-8')\n",
    "\n",
    "# text = 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.'\n",
    "\n",
    "# tokenized_text = word_tokenize(text)\n",
    "# classified_text = st.tag(tokenized_text)\n",
    "\n",
    "# print(classified_text)\n",
    "\n",
    "# nltk.download('words')\n",
    "# for i in df['Post_text'].dropna():\n",
    "#     print(i)\n",
    "#     extract_entities(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('model', 4.3141860046725258), ('described', 4.3141860046725258), ('lectures', 4.3141860046725258), ('pane', 4.3141860046725258), ('glass', 4.3141860046725258), ('absorbs', 4.3141860046725258), ('radiation', 4.3141860046725258), ('layer', 4.3141860046725258), ('ground', 4.3141860046725258), ('escapes', 4.3141860046725258), ('directly', 4.3141860046725258), ('greenhouse', 4.3141860046725258), ('formed', 4.3141860046725258), ('matthew', 4.3141860046725258), ('really', 4.3141860046725258), ('ahead', 4.3141860046725258), ('features', 4.3141860046725258), ('splendid', 4.3141860046725258), ('francois', 4.3141860046725258), ('link', 4.3141860046725258), ('good', 4.3141860046725258), ('answer', 4.3141860046725258), ('space', 4.3141860046725258), ('works', 4.3141860046725258), ('believe', 4.3141860046725258), ('subject', 4.3141860046725258), ('culture', 4.3141860046725258), ('cindy', 4.3141860046725258), ('sherman', 4.3141860046725258), ('dialogue', 4.3141860046725258)]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nvectorizer = TfidfVectorizer()\\n\\nposts=df_train['Post_text'].dropna().tolist()\\nvectorizer.fit(posts)\\n#print(vectorizer.vocabulary_)\\nprint(vectorizer.idf_)\\nvector = vectorizer.transform([posts[0]])\\nprint(vector.shape)\\nprint(vector.toarray())\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['resolves','elaborates','social','requests']\n",
    "courses = df['Course'].unique()\n",
    "\n",
    "for course in courses:\n",
    "    course_data = df.loc[df['Course']==course].dropna()\n",
    "    post_text = course_data['Post_text'].tolist()\n",
    "    course_train, course_val, course_test = np.split(course_data.sample(frac=1), [int(.6*len(course_data)), int(.8*len(course_data))])    \n",
    "df = df.dropna()\n",
    "#df_train, df_val, df_test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])    \n",
    "df_train, df_val, y_train, y_val = train_test_split(df.loc[:,'Post_text':'Comment_count'],df['Categories'],test_size=0.40,stratify=df['Categories']) \n",
    "#print(df_val)\n",
    "count_vect = CountVectorizer()\n",
    "df_train_counts = count_vect.fit_transform(df_train['Post_text'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "df_train_tfidf = tfidf_vectorizer.fit(df_train['Post_text'])\n",
    "text=df_train['Post_text'].tolist()\n",
    "#print(text[0])\n",
    "X = df_train_tfidf.transform([text[0]])\n",
    "#print(tfidf_vectorizer.vocabulary_)\n",
    "#print(X)\n",
    "#words_list = list(tfidf_vectorizer.vocabulary_.keys())\n",
    "#print(words_list)\n",
    "#print(sorted(tfidf_vectorizer.vocabulary_,key=tfidf_vectorizer.vocabulary_.get, reverse=True))\n",
    "new_dict={}\n",
    "#print(tfidf_vectorizer.idf_)\n",
    "for vocab, idf_score in zip((list(tfidf_vectorizer.vocabulary_.keys())),(tfidf_vectorizer.idf_)):\n",
    "    #print(vocab,idf_score)\n",
    "    if len(vocab)>3:\n",
    "        new_dict[vocab] = idf_score\n",
    "print(sorted(new_dict.items(),key=operator.itemgetter(1),reverse=True)[:30])\n",
    "\n",
    "print((X.toarray()))\n",
    "'''\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "posts=df_train['Post_text'].dropna().tolist()\n",
    "vectorizer.fit(posts)\n",
    "#print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "vector = vectorizer.transform([posts[0]])\n",
    "print(vector.shape)\n",
    "print(vector.toarray())\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TO DO --  get tf-idf scores from google-ngram-corpus?\n",
    "\n",
    "# from google_ngram_downloader import readline_google_store\n",
    "# for word in words_list:\n",
    "#     count = 0\n",
    "#     fname, url, records = next(readline_google_store(ngram_len=1, indices=word[0]))\n",
    " \n",
    "#     try:\n",
    "#         record = next(records)\n",
    "\n",
    "#         while record.ngram != word:\n",
    "#             record = next(records)\n",
    "\n",
    "#         while record.ngram == word:\n",
    "#             count = count + record.match_count\n",
    "#             record = next(records)\n",
    "\n",
    "#     except StopIteration:\n",
    "#         pass\n",
    "#     print(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "Actual: [1, 0, 1, 0, 3, 1, 1, 2, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 2, 0, 0, 1, 3, 1, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0]\n",
      "Accuracy: 0.540540540541\n",
      "\n",
      "---resolves---\n",
      "gentle\n",
      "constraint\n",
      "question\n",
      "answer\n",
      "synonymous\n",
      "force\n",
      "kc\n",
      "ball\n",
      "marriage\n",
      "line\n",
      "explanation\n",
      "noise\n",
      "miss\n",
      "bars\n",
      "file\n",
      "---elaborates---\n",
      "root\n",
      "artist\n",
      "concentration\n",
      "bar\n",
      "distribution\n",
      "5th\n",
      "screen tests\n",
      "tests\n",
      "screen\n",
      "negative\n",
      "andy\n",
      "conceptual\n",
      "art\n",
      "rate\n",
      "warhol\n",
      "---social---\n",
      "vec begin\n",
      "v_f\n",
      "tw_f\n",
      "pmatrix end\n",
      "slide\n",
      "begin\n",
      "nbsp nbsp\n",
      "urlref4\n",
      "14\n",
      "course\n",
      "end pmatrix\n",
      "begin pmatrix\n",
      "nbsp\n",
      "vec\n",
      "pmatrix\n",
      "---requests---\n",
      "dr\n",
      "art\n",
      "dr zeger\n",
      "zeger\n",
      "solved\n",
      "learn\n",
      "concepts\n",
      "doing\n",
      "learn doing\n",
      "damien\n",
      "damien hirst\n",
      "jeff koons\n",
      "hirst\n",
      "jeff\n",
      "koons\n"
     ]
    }
   ],
   "source": [
    "class_weights = {\n",
    "    0: 1.,\n",
    "    1: 1.,\n",
    "    2: 5.,\n",
    "    3: 5.\n",
    "}\n",
    "\n",
    "\n",
    "# Linear SVM or SGDCLassifier with Hinge Loss\n",
    "print(\" Linear SVM of SGDClassifier with Hinge Loss - Accuracy and feature names for categories\")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer(stop_words='english',ngram_range=(1,2))),\n",
    "                     ('clf',  SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42 #class_weight=class_weights,\n",
    "                                            )),\n",
    "])\n",
    "text_clf.fit(df_train['Post_text'], y_train)  \n",
    "\n",
    "predicted = text_clf.predict(df_val['Post_text'])\n",
    "print(\"Predicted: \"+ str(predicted.tolist()))\n",
    "print(\"Actual: \" + str(y_val.tolist()))\n",
    "print(\"Accuracy: \"+ str(np.mean(predicted == y_val))+ \"\\n\")\n",
    "indices = (np.argsort(text_clf.named_steps['clf'].coef_,axis=1))\n",
    "#print(indices)\n",
    "features = (text_clf.named_steps['tfidf'].get_feature_names())\n",
    "for i in indices:\n",
    "    print(\"---\"+ str(categories[np.where(np.all(indices==i,axis=1))[0][0]]) + \"---\")\n",
    "    for j in i[-15:]:\n",
    "        print(features[j])\n",
    "      \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Linear SVM or SGDCLassifier with Hinge Loss------------\n",
      "\n",
      "\n",
      "[[16  3  0  0]\n",
      " [ 9  3  0  0]\n",
      " [ 3  0  1  0]\n",
      " [ 1  1  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.84      0.67        19\n",
      "          1       0.43      0.25      0.32        12\n",
      "          2       1.00      0.25      0.40         4\n",
      "          3       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.53      0.54      0.49        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhikanikam/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('----------Linear SVM or SGDCLassifier with Hinge Loss------------\\n\\n')\n",
    "print(metrics.confusion_matrix(y_val, predicted))\n",
    "print(metrics.classification_report(y_val, predicted))\n",
    "\n",
    "# scores = cross_val_score(\n",
    "#     text_clf, X, df_val['Categories'], cv=2, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [0, 1, 0, 2, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0]\n",
      "Actual: [1, 0, 1, 0, 3, 1, 1, 2, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 2, 0, 0, 1, 3, 1, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0]\n",
      "Accuracy: 0.486486486486\n",
      "\n",
      "\n",
      "Most important features: \n",
      "\n",
      "just\n",
      "test\n",
      "art\n",
      "cool\n",
      "similar\n",
      "totally\n",
      "agree\n",
      "product\n",
      "fifth\n",
      "14\n",
      "going\n",
      "warhol\n",
      "guess\n",
      "rate\n",
      "explain\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosted Trees\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document \"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'length': len(text)\n",
    "                }\n",
    "                for text in posts]\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "text_clf = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "                     \n",
    "                     ('to_dense', DenseTransformer()),\n",
    "                     \n",
    "                     ('clf', GradientBoostingClassifier(random_state=42\n",
    "                                            )),\n",
    "])\n",
    "\n",
    "\n",
    "print('Gradient Boosted Trees -Accuracy and Most Important Features')\n",
    "\n",
    "text_clf.fit(df_train['Post_text'], y_train,)  \n",
    "\n",
    "predicted = text_clf.predict(df_val['Post_text'])\n",
    "#print(df_val['Post_text'],y_val)\n",
    "print(\"Predicted: \"+ str(predicted.tolist()))\n",
    "print(\"Actual: \" + str(y_val.tolist()))\n",
    "print(\"Accuracy: \"+ str(np.mean(predicted == y_val))+ \"\\n\")\n",
    "\n",
    "\n",
    "#print(np.sort(text_clf.named_steps['clf'].feature_importances_))\n",
    "indices = np.argsort(text_clf.named_steps['clf'].feature_importances_)[-15:]\n",
    "\n",
    "\n",
    "features = (text_clf.named_steps['tfidf'].get_feature_names())\n",
    "print(\"\\nMost important features: \\n\")\n",
    "for i in indices:\n",
    "    print(features[i])\n",
    "# important_features_dict = {}\n",
    "# for x,i in enumerate(text_clf.named_steps['clf'].feature_importances_):\n",
    "#     important_features_dict[x]=i\n",
    "\n",
    "\n",
    "# important_features_list = sorted(important_features_dict,\n",
    "#                                  key=important_features_dict.get,\n",
    "#                                  reverse=True)\n",
    "\n",
    "# print('Most important features: %s' %important_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Gradient Boosted Trees------------\n",
      "\n",
      "\n",
      "[[14  4  1  0]\n",
      " [ 8  4  0  0]\n",
      " [ 2  2  0  0]\n",
      " [ 1  1  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.74      0.64        19\n",
      "          1       0.36      0.33      0.35        12\n",
      "          2       0.00      0.00      0.00         4\n",
      "          3       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.41      0.49      0.44        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhikanikam/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('----------Gradient Boosted Trees------------\\n\\n')\n",
    "print(metrics.confusion_matrix(y_val, predicted))\n",
    "print(metrics.classification_report(y_val, predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Actual: [1, 0, 1, 0, 3, 1, 1, 2, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 2, 0, 0, 1, 3, 1, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0]\n",
      "Accuracy: 0.513513513514\n",
      "\n",
      "\n",
      "Most important features: \n",
      "\n",
      "using\n",
      "league\n",
      "film\n",
      "product\n",
      "personally\n",
      "discuss specific\n",
      "andy\n",
      "think\n",
      "questions\n",
      "derivative crass\n",
      "urlref4 problem\n",
      "begin\n",
      "art\n",
      "displayed properly\n",
      "presented lecture\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Pipeline\n",
    "\n",
    "text_clf = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "                     \n",
    "                     ('to_dense', DenseTransformer()),\n",
    "                     \n",
    "                     ('clf', RandomForestClassifier(class_weight=class_weights,random_state=42\n",
    "                                            )),\n",
    "])\n",
    "\n",
    "\n",
    "print('Random Forest Pipeline - Accuracy and Most Important Features ')\n",
    "\n",
    "text_clf.fit(df_train['Post_text'], y_train)  \n",
    "\n",
    "predicted = text_clf.predict(df_val['Post_text'])\n",
    "#print(df_val['Post_text'],y_val)\n",
    "print(\"Predicted: \"+ str(predicted.tolist()))\n",
    "print(\"Actual: \" + str(y_val.tolist()))\n",
    "print(\"Accuracy: \"+ str(np.mean(predicted == y_val))+ \"\\n\")\n",
    "\n",
    "#print(np.sort(text_clf.named_steps['clf'].feature_importances_))\n",
    "indices = np.argsort(text_clf.named_steps['clf'].feature_importances_)[-15:]\n",
    "#print(indices)\n",
    "\n",
    "features = (text_clf.named_steps['tfidf'].get_feature_names())\n",
    "print(\"\\nMost important features: \\n\")\n",
    "for i in indices:\n",
    "    print(features[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Random Forest------------\n",
      "\n",
      "\n",
      "[[18  1  0  0]\n",
      " [10  1  1  0]\n",
      " [ 3  1  0  0]\n",
      " [ 2  0  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.95      0.69        19\n",
      "          1       0.33      0.08      0.13        12\n",
      "          2       0.00      0.00      0.00         4\n",
      "          3       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.39      0.51      0.40        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhikanikam/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('----------Random Forest------------\\n\\n')\n",
    "print(metrics.confusion_matrix(y_val, predicted))\n",
    "print(metrics.classification_report(y_val, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Download and Import glove \n",
    "'''\n",
    "print('Download and import glove word embeddings to get the word vectors')\n",
    "\n",
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "df = pd.read_csv('../data/21total_preprocessed.csv').dropna(subset=['Post_text'])\n",
    "del df['Task2.1']\n",
    "df['Categories'] = df['Categories'].factorize()[0]\n",
    "texts = df['Post_text']\n",
    "print((texts[0][0]))\n",
    "labels = df['Categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7016 unique tokens.\n",
      "{'the': 1, 'to': 2, 'of': 3, 'i': 4, 'is': 5, 'a': 6, 'and': 7, 'in': 8, 'that': 9, 'it': 10, 'for': 11, 'this': 12, 'you': 13, 'as': 14, 'be': 15, 'not': 16, 'on': 17, 'but': 18, 'are': 19, 'with': 20, 'have': 21, 'was': 22, '\\xa0': 23, 'if': 24, 'or': 25, 'from': 26, 'so': 27, 'what': 28, 'would': 29, 'at': 30, 'we': 31, 'can': 32, 'about': 33, 'an': 34, 'by': 35, 'think': 36, '1': 37, 'his': 38, 'there': 39, 'art': 40, '2': 41, 'warhol': 42, 'all': 43, 'he': 44, 'one': 45, 'urlref': 46, 'more': 47, 'will': 48, 'my': 49, 'same': 50, 'when': 51, 'just': 52, 'me': 53, 'do': 54, 'some': 55, 'like': 56, 'how': 57, 'they': 58, 'math': 59, '0': 60, 'time': 61, 'which': 62, 'question': 63, 'lecture': 64, 'get': 65, 'has': 66, 'am': 67, 'other': 68, 'very': 69, 'then': 70, 'work': 71, 'see': 72, 'your': 73, 'because': 74, 'no': 75, 'course': 76, 'way': 77, 'than': 78, 'also': 79, \"i'm\": 80, 'know': 81, 'could': 82, 'answer': 83, 'out': 84, 'first': 85, \"don't\": 86, 'why': 87, \"it's\": 88, 'only': 89, 'point': 90, 'does': 91, 'any': 92, 'up': 93, 'here': 94, 'e': 95, '4': 96, 'problem': 97, 'into': 98, 'had': 99, 'them': 100, 'thanks': 101, 'should': 102, 'these': 103, 'different': 104, 'really': 105, 'correct': 106, 'energy': 107, 'use': 108, 'understand': 109, '3': 110, 'hi': 111, 'right': 112, 'did': 113, 'where': 114, 'something': 115, 'seems': 116, 'mean': 117, 'were': 118, 'their': 119, 'example': 120, 'who': 121, 'been': 122, 'value': 123, 'much': 124, 'being': 125, '5': 126, 'used': 127, 'too': 128, 'well': 129, 'force': 130, 'film': 131, 'find': 132, 'case': 133, 'two': 134, 'even': 135, 'page': 136, 'say': 137, 'wrong': 138, 'marriage': 139, 'each': 140, 'part': 141, 'between': 142, 'many': 143, 'using': 144, 'need': 145, 'its': 146, 'works': 147, 'andy': 148, 'still': 149, 'video': 150, 'instruction': 151, 'rate': 152, 'quiz': 153, 'sure': 154, 'might': 155, 'interesting': 156, 'may': 157, 'now': 158, 'set': 159, 'since': 160, 'another': 161, 'back': 162, \"warhol's\": 163, 'take': 164, 'thought': 165, 'us': 166, 'function': 167, 'her': 168, 'distribution': 169, 'both': 170, 'week': 171, 'those': 172, 'make': 173, 'people': 174, 'p': 175, 'our': 176, 'over': 177, 'movie': 178, 'please': 179, 'units': 180, 'last': 181, 'good': 182, 'going': 183, 'after': 184, 'most': 185, 's': 186, 'error': 187, 'she': 188, 'equilibrium': 189, 'conceptual': 190, 'while': 191, 'down': 192, 'always': 193, 'data': 194, 'memory': 195, 'during': 196, 'change': 197, 'him': 198, 'line': 199, 'state': 200, 'b': 201, 'above': 202, 'artist': 203, '10': 204, 'thread': 205, 'yes': 206, 'weights': 207, 'read': 208, 'however': 209, 'post': 210, 'w': 211, 'made': 212, 'artists': 213, 'idea': 214, 'got': 215, 'screen': 216, 'without': 217, 'such': 218, 'great': 219, 'having': 220, 'new': 221, 'link': 222, \"can't\": 223, 'anyone': 224, 'file': 225, 'second': 226, 'actually': 227, 'want': 228, 'm': 229, 'money': 230, 'world': 231, 'times': 232, 'must': 233, 'lectures': 234, 'etc': 235, 'end': 236, 'cache': 237, 'believe': 238, 'y': 239, \"doesn't\": 240, 'help': 241, 'zero': 242, 'through': 243, 'though': 244, 'given': 245, 'celebrity': 246, 'said': 247, 'doing': 248, 'number': 249, 'guess': 250, 'v': 251, 'makes': 252, 'weight': 253, 'thermal': 254, 'solution': 255, 'agree': 256, 'images': 257, 'cycle': 258, 'reaction': 259, 'tests': 260, 'put': 261, 'few': 262, 'hope': 263, 'someone': 264, 'little': 265, 'top': 266, '6': 267, 'miss': 268, 'look': 269, 'perhaps': 270, 'order': 271, 'address': 272, 'network': 273, 'k': 274, \"that's\": 275, 'unit': 276, 'pop': 277, 'mentioned': 278, 'n': 279, 'friction': 280, 'before': 281, 'probability': 282, 'next': 283, 'around': 284, 'means': 285, 'looking': 286, 'slide': 287, 'states': 288, 'explanation': 289, 'done': 290, 'difference': 291, 'things': 292, 'test': 293, 'negative': 294, 'system': 295, 'velocity': 296, 'trying': 297, 'cannot': 298, '8': 299, 'wonder': 300, 'found': 301, 'maybe': 302, 'whether': 303, 'movies': 304, 'feel': 305, 'points': 306, 'bit': 307, 'go': 308, 'under': 309, 'either': 310, 'result': 311, 'left': 312, 'lab': 313, 'c': 314, 'probably': 315, 'kind': 316, 'life': 317, 'taken': 318, 'try': 319, 'seem': 320, 'thinking': 321, 'write': 322, 'random': 323, 'instructions': 324, \"didn't\": 325, 'bits': 326, 'values': 327, 'important': 328, 'love': 329, \"isn't\": 330, 'long': 331, 'less': 332, 'true': 333, 'own': 334, 'able': 335, 'give': 336, 'thank': 337, 'process': 338, 'better': 339, 'following': 340, 'questions': 341, 'concept': 342, 'average': 343, 'object': 344, 'initial': 345, 'wheel': 346, 'thing': 347, 'issue': 348, 'h': 349, 'yet': 350, 'videos': 351, 'view': 352, 'space': 353, 'years': 354, 'real': 355, 'explain': 356, 'missing': 357, 'person': 358, 'learn': 359, 'sample': 360, 'x': 361, 'level': 362, 'model': 363, 'lot': 364, 'net': 365, 'training': 366, 'boltzmann': 367, 'f': 368, 'today': 369, 'box': 370, 'acceleration': 371, 'term': 372, 'sense': 373, 'clear': 374, 'certain': 375, 'due': 376, 'together': 377, 'problems': 378, 'rather': 379, 'says': 380, 'co2': 381, 'constant': 382, 'celebrities': 383, 'inputs': 384, 'present': 385, 'download': 386, 'therefore': 387, 'again': 388, 'sequence': 389, 'enough': 390, 'discussion': 391, '7': 392, 'working': 393, 'least': 394, 'fact': 395, 'linear': 396, 'effect': 397, 'off': 398, 'quite': 399, 'stage': 400, 'information': 401, 'watching': 402, 'sequences': 403, 'once': 404, 'hit': 405, 'output': 406, 'far': 407, 'learning': 408, 'mass': 409, 'statement': 410, 'films': 411, 'couple': 412, 'final': 413, 'form': 414, 'already': 415, 'three': 416, 'consider': 417, 't': 418, 'surface': 419, 'away': 420, 'terms': 421, 'show': 422, 'image': 423, 'below': 424, 'configuration': 425, 'machine': 426, 'understanding': 427, 'meaning': 428, 'ground': 429, 'law': 430, 'hard': 431, 'culture': 432, 'best': 433, 'come': 434, \"i'd\": 435, 'check': 436, 'earth': 437, 'took': 438, 'similar': 439, 'subject': 440, 'according': 441, 'mind': 442, 'forward': 443, 'else': 444, 'add': 445, '11': 446, 'move': 447, '100': 448, 'professor': 449, 'instead': 450, 'near': 451, 'anything': 452, 'specific': 453, 'watch': 454, 'hand': 455, 'assume': 456, 'full': 457, 'married': 458, 'original': 459, 'modern': 460, 'making': 461, '20': 462, 'hinton': 463, 'noise': 464, '12': 465, 'register': 466, 'processor': 467, 'human': 468, 'possible': 469, 'forum': 470, 'material': 471, 'length': 472, 'likelihood': 473, 'method': 474, 'positive': 475, 'non': 476, 'understood': 477, 'correctly': 478, 'wanted': 479, 'worked': 480, 'tried': 481, 'message': 482, 'fine': 483, 'practice': 484, 'save': 485, 'let': 486, 'equation': 487, 'chemistry': 488, 'half': 489, 'store': 490, 'concentration': 491, 'prof': 492, 'never': 493, 'product': 494, 'soup': 495, 'transition': 496, 'pipeline': 497, 'seen': 498, 'available': 499, 'step': 500, 'keep': 501, 'although': 502, 'target': 503, 'comes': 504, 'simple': 505, 'j': 506, 'others': 507, 'reason': 508, 'steps': 509, 'exactly': 510, 'ways': 511, 'gets': 512, 'examples': 513, 'english': 514, 'simply': 515, 'standard': 516, 'feedback': 517, 'wagon': 518, 'remember': 519, 'rule': 520, '14': 521, 'class': 522, 'famous': 523, 'general': 524, 'hidden': 525, 'precise': 526, 'registers': 527, 'answers': 528, 'start': 529, '9': 530, 'minutes': 531, 'click': 532, 'every': 533, 'confused': 534, 'getting': 535, 'nodes': 536, 'variable': 537, 'increase': 538, 'comment': 539, 'helps': 540, 'everyone': 541, '2012': 542, 'saw': 543, 'until': 544, 'table': 545, 'update': 546, 'totally': 547, 'suppose': 548, 'share': 549, 'single': 550, 'homework': 551, 'relationship': 552, 'definition': 553, 'based': 554, 'threads': 555, 'takes': 556, 'rob': 557, 'u': 558, 'block': 559, 'open': 560, 'went': 561, 'assignment': 562, 'later': 563, 'results': 564, 'sorry': 565, 'courses': 566, 'early': 567, 'late': 568, 'rest': 569, 'required': 570, 'situation': 571, 'estimate': 572, 'attention': 573, 'run': 574, 'id': 575, 'solve': 576, 'cause': 577, 'seeing': 578, 'water': 579, 'gas': 580, 'ball': 581, \"you're\": 582, 'front': 583, 'needs': 584, 'sometimes': 585, 'lb': 586, \"wouldn't\": 587, 'marilyn': 588, 'society': 589, '15': 590, 'solutions': 591, 'detailed': 592, 'frac': 593, 'kc': 594, 'tlb': 595, 'personal': 596, 'experience': 597, 'adding': 598, 'staff': 599, 'gave': 600, 'hold': 601, 'came': 602, 'directly': 603, 'calculate': 604, 'happen': 605, 'physical': 606, 'useful': 607, 'timeref': 608, 'ones': 609, 'almost': 610, 'figure': 611, 'local': 612, 'matrix': 613, 'everything': 614, 'summary': 615, 'input': 616, 'added': 617, 'sort': 618, 'reading': 619, '001': 620, 'wondering': 621, 'incorrect': 622, 'assuming': 623, 'asked': 624, 'physics': 625, 'direction': 626, 'day': 627, 'free': 628, 'considered': 629, 'live': 630, 'family': 631, 'contemporary': 632, 'media': 633, 'sets': 634, 'taking': 635, 'recurrent': 636, 'pmatrix': 637, \"haven't\": 638, 'hours': 639, 'load': 640, 'pictures': 641, 'short': 642, 'study': 643, 're': 644, 'amount': 645, 'students': 646, 'man': 647, 'place': 648, 'along': 649, 'body': 650, 'calculation': 651, 'distance': 652, 'entry': 653, 'among': 654, 'mega': 655, 'lost': 656, 'g': 657, 'population': 658, 'shows': 659, 'lines': 660, 'purpose': 661, 'often': 662, '16': 663, 'd': 664, 'matter': 665, 'third': 666, 'match': 667, 'saying': 668, 'factor': 669, 'mother': 670, 'appreciate': 671, 'nothing': 672, 'group': 673, 'support': 674, 'lr': 675, 'layer': 676, 'high': 677, 'became': 678, 'equal': 679, \"there's\": 680, 'story': 681, 'imagine': 682, 'death': 683, 'sexuality': 684, 'subjects': 685, 'become': 686, 'nets': 687, 'prove': 688, 'pc': 689, 'instr': 690, 'cpu': 691, 'decode': 692, 'book': 693, 'stated': 694, 'ago': 695, 'name': 696, 'started': 697, 'atmosphere': 698, 'article': 699, 'word': 700, 'obvious': 701, 'concepts': 702, 'shown': 703, 'further': 704, 'samples': 705, 'algorithm': 706, 'large': 707, \"i've\": 708, 'type': 709, 'changes': 710, 'red': 711, 'features': 712, 'neural': 713, 'networks': 714, 'details': 715, \"'\": 716, 'downloaded': 717, '64': 718, 'computer': 719, 'moment': 720, 'build': 721, 'missed': 722, 'several': 723, 'mistake': 724, 'whole': 725, 'path': 726, 'described': 727, 'ideas': 728, 'temperature': 729, 'logistic': 730, 'relative': 731, 'curious': 732, 'power': 733, 'context': 734, 'heat': 735, 'old': 736, 'gravity': 737, 'reach': 738, 'himself': 739, 'building': 740, 'century': 741, 'husband': 742, 'worth': 743, 'american': 744, 'behind': 745, 'particular': 746, 'create': 747, 'repetition': 748, 'including': 749, 'content': 750, 'hollywood': 751, 'giving': 752, 'status': 753, 'guggenheim': 754, 'critique': 755, 'expected': 756, 'vector': 757, 'pipe': 758, 'median': 759, 'stratum': 760, 'precision': 761, 'btb': 762, 'caches': 763, 'close': 764, 'text': 765, 'round': 766, 'bad': 767, 'main': 768, 'lower': 769, \"i'll\": 770, 'played': 771, 'rotation': 772, 'nice': 773, 'history': 774, 'related': 775, 'node': 776, 'increases': 777, 'ratio': 778, 'occur': 779, 'bias': 780, 'impact': 781, 'changing': 782, \"aren't\": 783, 'easier': 784, \"they're\": 785, 'hello': 786, '\\xa0i': 787, 'anybody': 788, 'list': 789, 'looks': 790, 'contains': 791, 'appear': 792, 'pretty': 793, 'option': 794, 'parameters': 795, 'exact': 796, 'usually': 797, 'log': 798, 'ending': 799, 'per': 800, 'models': 801, 'hence': 802, 'certainly': 803, 'greenhouse': 804, 'light': 805, 'called': 806, 'interested': 807, 'momentum': 808, 'hill': 809, 'uses': 810, 'wrote': 811, 'earlier': 812, 'motion': 813, 'static': 814, 'nature': 815, 'upon': 816, 'happens': 817, 'wants': 818, 'somehow': 819, \"you've\": 820, 'definitely': 821, 'john': 822, 'released': 823, 'board': 824, 'factory': 825, 'sex': 826, 'album': 827, 'interest': 828, 'artwork': 829, 'wall': 830, 'piece': 831, 'logic': 832, 'shared': 833, 'business': 834, 'collection': 835, '50': 836, 'hirst': 837, 'koons': 838, 'looked': 839, 'against': 840, 'unique': 841, \"we're\": 842, 'starting': 843, 'begin': 844, 'hopfield': 845, 'balance': 846, 'determine': 847, 'variance': 848, 'kinetics': 849, 'reactant': 850, 'commit': 851, 'lanes': 852, 'buffer': 853, 'veggies': 854, 'r10': 855, 'ft': 856, 'across': 857, 'sign': 858, 'clarify': 859, 'posting': 860, 'internet': 861, 'clock': 862, 'mantle': 863, 'side': 864, 'program': 865, 'numbers': 866, 'km': 867, 'drop': 868, 'slides': 869, 'application': 870, 'dr': 871, 'alignment': 872, 'bottom': 873, 'clearly': 874, 'vs': 875, 'call': 876, 'known': 877, 'appreciated': 878, 'finding': 879, 'coursera': 880, 'checked': 881, 'exception': 882, 'gives': 883, 'score': 884, 'r': 885, 'files': 886, 'extension': 887, 'valid': 888, 'boring': 889, 'created': 890, 'current': 891, 'common': 892, 'myself': 893, 'knowledge': 894, 'appropriate': 895, 'prices': 896, 'price': 897, 'q3': 898, 'rise': 899, 'warming': 900, 'plus': 901, 'ok': 902, 'provided': 903, 'defined': 904, 'causes': 905, 'low': 906, 'needed': 907, 'moving': 908, 'influence': 909, 'hear': 910, 'head': 911, \"couldn't\": 912, 'center': 913, 'turn': 914, 'food': 915, 'completely': 916, 'moon': 917, 'lowest': 918, 'perfect': 919, 'response': 920, 'character': 921, 'painting': 922, 'aware': 923, 'specifically': 924, 'itself': 925, 'beyond': 926, 'cans': 927, 'viewing': 928, 'gay': 929, 'market': 930, 'deep': 931, 'visual': 932, \"andy's\": 933, 'artistic': 934, 'cases': 935, 'cost': 936, 'damien': 937, 'derivative': 938, 'aesthetic': 939, 'multiple': 940, 'viewer': 941, 'normal': 942, 'sit': 943, 'contact': 944, 'h1': 945, 'h2': 946, 'parallel': 947, 'finite': 948, 'binary': 949, 'statistics': 950, 'machines': 951, 'sigma': 952, 'expectation': 953, 'posterior': 954, 'rbm': 955, 'p1': 956, 'accuracy': 957, 'mscd': 958, 'hypothesis': 959, 'branch': 960, 'inside': 961, 'simd': 962, 'insert': 963, 'directory': 964, 'past': 965, 'weeks': 966, 'anyway': 967, 'occurs': 968, 'days': 969, 'ask': 970, \"you'll\": 971, 'info': 972, 'include': 973, 'fall': 974, 'flow': 975, 'written': 976, 'popular': 977, 'likely': 978, 'tell': 979, 'excellent': 980, 'methods': 981, 'tools': 982, 'versions': 983, 'column': 984, 'ml': 985, 'position': 986, 'synonymous': 987, 'selection': 988, 'expect': 989, 'higher': 990, 'goes': 991, 'effects': 992, 'pdf': 993, 'select': 994, 'comparison': 995, 'search': 996, 'java': 997, 'particularly': 998, 'site': 999, 'deal': 1000, '13': 1001, 'trouble': 1002, 'bar': 1003, 'finally': 1004, 'confusion': 1005, \"wasn't\": 1006, 'editor': 1007, 'convert': 1008, 'background': 1009, 'four': 1010, 'index': 1011, 'note': 1012, 'access': 1013, 'calculations': 1014, 'z': 1015, 'topic': 1016, \"he's\": 1017, 'watched': 1018, 'exists': 1019, 'regards': 1020, 'heard': 1021, 'formula': 1022, 'significant': 1023, 'vapor': 1024, 'acting': 1025, 'applied': 1026, 'stay': 1027, 'indeed': 1028, 'radiation': 1029, 'increasing': 1030, 'meant': 1031, 'assumption': 1032, 'visible': 1033, 'classes': 1034, 'small': 1035, 'recently': 1036, 'copyright': 1037, 'reality': 1038, 'torque': 1039, 'involved': 1040, 'difficulty': 1041, 'towards': 1042, 'gravitational': 1043, 'potential': 1044, 'spring': 1045, 'forces': 1046, 'act': 1047, 'highly': 1048, 'happy': 1049, 'train': 1050, 'kg': 1051, 'unless': 1052, 'home': 1053, 'woman': 1054, 'ever': 1055, 'theme': 1056, 'future': 1057, 'cover': 1058, 'previous': 1059, 'public': 1060, 'play': 1061, 'equivalent': 1062, 'produced': 1063, 'beautiful': 1064, 'living': 1065, 'david': 1066, 'success': 1067, 'occurred': 1068, 'design': 1069, 'america': 1070, 'feed': 1071, 'writing': 1072, 'influenced': 1073, 'admit': 1074, 'openly': 1075, 'expression': 1076, 'church': 1077, 'died': 1078, 'necessarily': 1079, '000': 1080, 'dollars': 1081, 'expert': 1082, 'jeff': 1083, 'fit': 1084, 'feature': 1085, 'chain': 1086, 'moved': 1087, 'objective': 1088, 'feasible': 1089, 'proof': 1090, 'statistical': 1091, 'markov': 1092, 'stationary': 1093, 'propagation': 1094, 'exam': 1095, 'phase': 1096, 'connections': 1097, 'constraint': 1098, 'vec': 1099, '25': 1100, 'nbsp': 1101, 'lane': 1102, 'fetch': 1103, 'r6': 1104, 'diagram': 1105, '4096': 1106, 'fascinating': 1107, 'discovered': 1108, 'document': 1109, 'finish': 1110, 'field': 1111, 'student': 1112, 'discussed': 1113, 'wiki': 1114, 'asking': 1115, 'larger': 1116, 'typo': 1117, '24': 1118, 'actions': 1119, 'easily': 1120, 'regarding': 1121, 'indicate': 1122, 'accurate': 1123, 'compute': 1124, 'pressures': 1125, 'proportion': 1126, 'code': 1127, 'subtle': 1128, 'blast': 1129, 'versus': 1130, 'version': 1131, 'follow': 1132, 'windows': 1133, 'display': 1134, 'options': 1135, 'copy': 1136, 'instructor': 1137, 'words': 1138, 'cheers': 1139, 'displayed': 1140, 'location': 1141, 'knows': 1142, 'notice': 1143, 'risk': 1144, 'factors': 1145, 'loss': 1146, 'opinion': 1147, 'big': 1148, 'section': 1149, \"what's\": 1150, 'sea': 1151, 'ice': 1152, 'levels': 1153, 'puzzled': 1154, 'production': 1155, 'exponential': 1156, 'demand': 1157, 'describe': 1158, 'generate': 1159, 'leads': 1160, 'total': 1161, 'activities': 1162, 'depth': 1163, 'global': 1164, 'greater': 1165, 'brought': 1166, 'prior': 1167, 'decreasing': 1168, 'glass': 1169, 'concentrations': 1170, 'online': 1171, 'laws': 1172, 'tv': 1173, 'face': 1174, 'putting': 1175, 'derivation': 1176, 'falling': 1177, 'currently': 1178, 'cutting': 1179, 'central': 1180, 'job': 1181, 'strong': 1182, 'complicated': 1183, 'characters': 1184, 'especially': 1185, 'french': 1186, 'television': 1187, 'lead': 1188, 'performance': 1189, 'interview': 1190, 'commercial': 1191, \"campbell's\": 1192, 'magazine': 1193, 'materials': 1194, 'themes': 1195, 'catholic': 1196, 'bought': 1197, 'slope': 1198, 'paintings': 1199, 'homosexuality': 1200, 'allowed': 1201, 'variables': 1202, 'vice': 1203, 'arts': 1204, 'alone': 1205, 'economic': 1206, 'pay': 1207, 'anonymous': 1208, 'individual': 1209, 'investment': 1210, 'hundred': 1211, 'lots': 1212, 'nor': 1213, 'necessary': 1214, 'products': 1215, 'tar': 1216, 'ready': 1217, 'viewed': 1218, 'within': 1219, 'size': 1220, 'portraits': 1221, 'style': 1222, 'supported': 1223, 'sherman': 1224, 'faster': 1225, 'respect': 1226, 'audio': 1227, 'minimum': 1228, 'cone': 1229, 'thus': 1230, 'weighted': 1231, 'paper': 1232, 'invariant': 1233, 'sum': 1234, 'configurations': 1235, \"shouldn't\": 1236, 'explained': 1237, 'unlearning': 1238, 'backpropagation': 1239, 'rbms': 1240, 'compare': 1241, 'digits': 1242, 'calculated': 1243, 'dropout': 1244, 'reasoning': 1245, 'urlref4': 1246, 'kp': 1247, 'submit': 1248, 'estimates': 1249, 'se': 1250, 'sigfigs': 1251, 'odds': 1252, 'blank': 1253, 'mesi': 1254, 'protocol': 1255, 'proc': 1256, 'stall': 1257, 'counter': 1258, 'entries': 1259, 'mul': 1260, 'metric': 1261, 'recent': 1262, 'effort': 1263, 'deadline': 1264, 'passed': 1265, 'spent': 1266, 'country': 1267, 'losing': 1268, 'israel': 1269, 'essay': 1270, 'independent': 1271, 'gases': 1272, 'happened': 1273, 'wonderful': 1274, 'allow': 1275, 'dealing': 1276, 'minute': 1277, 'direct': 1278, '400': 1279, 'frequency': 1280, 'liquid': 1281, 'mention': 1282, 'notes': 1283, 'aligned': 1284, '2nd': 1285, 'links': 1286, 'analysis': 1287, 'max': 1288, 'reference': 1289, 'o': 1290, 'maximum': 1291, 'suggest': 1292, 'bring': 1293, 'representation': 1294, 'reverse': 1295, 'report': 1296, 'represent': 1297, 'mouse': 1298, 'compared': 1299, 'advance': 1300, 'choose': 1301, 'snapshot': 1302, 'updated': 1303, 'talk': 1304, 'color': 1305, 'soon': 1306, 'graphical': 1307, 'whereas': 1308, 'default': 1309, 'white': 1310, 'whatever': 1311, 'middle': 1312, 'addition': 1313, 'taxonomy': 1314, 'extremely': 1315, 'starts': 1316, 'fas': 1317, 'talking': 1318, 'stuck': 1319, 'control': 1320, 'hide': 1321, 'tree': 1322, 'five': 1323, 'names': 1324, 'suggested': 1325, 'poor': 1326, 'possibly': 1327, 'outcome': 1328, 'coming': 1329, 'besides': 1330, 'google': 1331, 'cells': 1332, 'provide': 1333, 'medieval': 1334, 'q4': 1335, 'somewhat': 1336, 'age': 1337, 'somewhere': 1338, 'gaussian': 1339, 'considering': 1340, 'cut': 1341, 'none': 1342, 'pound': 1343, 'ghg': 1344, '200': 1345, 'supposed': 1346, 'implies': 1347, 'assumed': 1348, 'throughout': 1349, 'height': 1350, 'presented': 1351, 'effective': 1352, 'altitude': 1353, 'downward': 1354, 'capacity': 1355, 'crazy': 1356, 'strange': 1357, 'practical': 1358, 'permission': 1359, 'air': 1360, \"let's\": 1361, 'bicycle': 1362, 'angular': 1363, 'doubt': 1364, 'knew': 1365, 'speed': 1366, 'otherwise': 1367, 'depends': 1368, 'exist': 1369, \"ball's\": 1370, 'rock': 1371, 'rear': 1372, 'completed': 1373, 'bullet': 1374, 'separate': 1375, 'university': 1376, 'pulling': 1377, 'cannon': 1378, 'yards': 1379, 'axis': 1380, 'differences': 1381, 'remain': 1382, 'professors': 1383, 'tables': 1384, 'ref': 1385, 'self': 1386, 'encounters': 1387, 'infidelity': 1388, 'desire': 1389, 'bored': 1390, 'surely': 1391, 'honest': 1392, 'bergman': 1393, 'women': 1394, 'boredom': 1395, 'drawn': 1396, 'hitchcock': 1397, 'johnny': 1398, 'walk': 1399, 'recognize': 1400, 'obviously': 1401, 'events': 1402, 'war': 1403, 'meet': 1404, 'source': 1405, 'shall': 1406, 'role': 1407, 'joseph': 1408, 'house': 1409, 'classify': 1410, 'series': 1411, 'social': 1412, 'iconic': 1413, 'apparently': 1414, 'signed': 1415, 'sued': 1416, 'gallery': 1417, 'basquiat': 1418, 'drawing': 1419, 'foundation': 1420, 'tate': 1421, 'male': 1422, 'music': 1423, 'vote': 1424, 'loved': 1425, 'youtube': 1426, 'colacello': 1427, 'comments': 1428, 'millions': 1429, 'buy': 1430, 'visited': 1431, 'symbol': 1432, 'selling': 1433, 'peggy': 1434, 'collecting': 1435, 'museum': 1436, 'mark': 1437, 'complete': 1438, 'beginning': 1439, 'choice': 1440, 'lisa': 1441, '2014': 1442, 'fame': 1443, 'whose': 1444, 'obsession': 1445, 'duchamp': 1446, 'desires': 1447, 'technique': 1448, 'sleep': 1449, 'waste': 1450, 'becomes': 1451, 'filmmaking': 1452, 'portrait': 1453, 'realized': 1454, 'monroe': 1455, 'multiplied': 1456, 'predicted': 1457, 'learned': 1458, 'cool': 1459, 'interpretation': 1460, 'hyperplane': 1461, 'probabilities': 1462, 'theorem': 1463, 'derive': 1464, 'equations': 1465, 'ends': 1466, 'settle': 1467, \"you'd\": 1468, 'computing': 1469, 'theory': 1470, 'feet': 1471, 'gates': 1472, 'implement': 1473, 'approximation': 1474, 'differ': 1475, 'smaller': 1476, 'backprop': 1477, 'experiment': 1478, 'posted': 1479, 'square': 1480, 'calculator': 1481, 'delta': 1482, 'expenditures': 1483, 'medians': 1484, '375': 1485, '36': 1486, '\\xa0cycle': 1487, '\\xa0br': 1488, 'processors': 1489, 'blocking': 1490, 'execute': 1491, 'virtual': 1492, 'stalled': 1493, 'r5': 1494, 'hazard': 1495, 'spaceship': 1496, 'salad': 1497, 'pushkal': 1498, 'decided': 1499, 'strict': 1500, 'count': 1501, 'upload': 1502, 'pics': 1503, 'yours': 1504, 'credit': 1505, 'user': 1506, 'luck': 1507, 'okay': 1508, 'repeat': 1509, 'request': 1510, 'chance': 1511, 'zvika': 1512, 'greenberg': 1513, 'haifa': 1514, '002': 1515, 'suggests': 1516, 'science': 1517, 'cope': 1518, 'scale': 1519, 'vectors': 1520, 'deeper': 1521, '26': 1522, 'afraid': 1523, 'evolutionary': 1524, 'fast': 1525, 'format': 1526, 'sampling': 1527, 'advantage': 1528, 'th': 1529, 'noticed': 1530, 'changed': 1531, 'effectively': 1532, 'degrees': 1533, 'argue': 1534, 'mutations': 1535, 'pressure': 1536, 'picture': 1537, 'thin': 1538, 'blue': 1539, 'genes': 1540, 'apply': 1541, 'conserved': 1542, 'offered': 1543, 'except': 1544, 'webact': 1545, 'unable': 1546, 'ken': 1547, 'issued': 1548, 'mac': 1549, 'told': 1550, '32': 1551, 'query': 1552, 'iteration': 1553, '1st': 1554, 'strategy': 1555, 'existence': 1556, 'showed': 1557, 'record': 1558, 'observations': 1559, 'beginners': 1560, 'optional': 1561, 'residues': 1562, 'website': 1563, 'opening': 1564, 'crimson': 1565, 'detail': 1566, 'appears': 1567, 'specify': 1568, '\\xa0you': 1569, 'measures': 1570, 'bootstrap': 1571, 'playing': 1572, 'consequence': 1573, 'icon': 1574, 'hoping': 1575, 'fix': 1576, 'tells': 1577, 'posts': 1578, 'showing': 1579, 'decide': 1580, 'comparing': 1581, 'titled': 1582, 'degree': 1583, 'advanced': 1584, 'rank': 1585, 'optimization': 1586, 'de': 1587, 'natural': 1588, 'peak': 1589, 'oil': 1590, 'latter': 1591, 'shaped': 1592, 'climate': 1593, 'clouds': 1594, 'coriolis': 1595, 'double': 1596, 'n2o': 1597, '40': 1598, '120': 1599, 'q5': 1600, 'leaving': 1601, 'ppm': 1602, 'boltzman': 1603, 'skin': 1604, 'upward': 1605, 'oh': 1606, 'setting': 1607, '23': 1608, 'chemical': 1609, 'thermodynamics': 1610, 'helpful': 1611, 'year': 1612, \"week's\": 1613, 'realistic': 1614, 'wish': 1615, 'directed': 1616, 'convention': 1617, 'applies': 1618, 'gone': 1619, 'bumper': 1620, 'accelerate': 1621, 'stop': 1622, 'inertial': 1623, 'movement': 1624, 'downhill': 1625, 'stops': 1626, 'slowing': 1627, 'mentions': 1628, 'cancel': 1629, 'objects': 1630, 'condition': 1631, 'slow': 1632, 'wasted': 1633, 'car': 1634, 'gun': 1635, 'mouth': 1636, 'stating': 1637, 'pounds': 1638, 'inertia': 1639, 'relate': 1640, 'care': 1641, 'laptop': 1642, 'cloth': 1643, 'slowly': 1644, 'overall': 1645, '\\x80\\x9cbefore': 1646, 'jeanine': 1647, 'brief': 1648, 'easy': 1649, 'outside': 1650, 'seemed': 1651, 'whom': 1652, 'actors': 1653, 'vincent': 1654, 'action': 1655, 'historical': 1656, 'enjoyed': 1657, 'spanish': 1658, 'eyes': 1659, 'powerful': 1660, 'liked': 1661, 'issues': 1662, 'wife': 1663, 'stories': 1664, 'friend': 1665, 'suspicion': 1666, 'cary': 1667, 'grant': 1668, 'aside': 1669, 'fun': 1670, 'perspective': 1671, 'return': 1672, 'audience': 1673, 'romantic': 1674, 'catch': 1675, 'kept': 1676, 'scene': 1677, 'title': 1678, 'running': 1679, 'situations': 1680, 'opinions': 1681, 'break': 1682, 'mad': 1683, 'survival': 1684, '1964': 1685, 'absolutely': 1686, 'thoughts': 1687, 'couples': 1688, 'tom': 1689, 'career': 1690, 'van': 1691, 'bill': 1692, 'lose': 1693, 'young': 1694, 'james': 1695, 'era': 1696, 'york': 1697, 'reads': 1698, 'jean': 1699, 'sexual': 1700, 'fully': 1701, 'pornography': 1702, 'quick': 1703, 'underground': 1704, 'successful': 1705, 'hundreds': 1706, 'essentially': 1707, 'unlike': 1708, 'offer': 1709, 'turned': 1710, 'game': 1711, 'photo': 1712, 'mystery': 1713, 'appearance': 1714, 'yourself': 1715, 'homoerotic': 1716, 'contemporaries': 1717, 'intellectual': 1718, 'insight': 1719, 'stand': 1720, 'statements': 1721, 'philosophy': 1722, 'bob': 1723, 'helped': 1724, 'artworks': 1725, 'hang': 1726, 'suspect': 1727, 'pollock': 1728, 'paint': 1729, 'dean': 1730, 'represents': 1731, 'refers': 1732, 'paid': 1733, 'circumstances': 1734, 'pieces': 1735, 'projects': 1736, 'mid': 1737, 'painted': 1738, 'combined': 1739, 'cultural': 1740, 'speaking': 1741, 'till': 1742, 'mapped': 1743, 'importance': 1744, 'creative': 1745, 'figures': 1746, 'perception': 1747, 'child': 1748, 'empire': 1749, 'hour': 1750, 'mooc': 1751, 'reactions': 1752, 'equally': 1753, 'relation': 1754, 'usa': 1755, 'forms': 1756, 'camera': 1757, 'un': 1758, 'julia': 1759, 'bay': 1760, 'pr': 1761, 'dirty': 1762, 'assessment': 1763, 'conclusion': 1764, 'super': 1765, 'procedure': 1766, 'fraud': 1767, 'scientific': 1768, 'reduce': 1769, 'naturally': 1770, 'instance': 1771, 'divide': 1772, 'neurons': 1773, 'yeah': 1774, 'infinity': 1775, 'label': 1776, 'predictions': 1777, 'autoencoders': 1778, 'storage': 1779, 'mistakes': 1780, 'terminology': 1781, 'introduces': 1782, 'deterministic': 1783, 'fixed': 1784, 'similarly': 1785, 'rightarrow': 1786, 'sounds': 1787, 'basically': 1788, 'somebody': 1789, 'gentle': 1790, 'computation': 1791, 'mixed': 1792, 'constraints': 1793, \"we've\": 1794, 'quadratic': 1795, 'rnn': 1796, 'decimal': 1797, 'involve': 1798, 'randomly': 1799, 'multiplication': 1800, 'multiply': 1801, 'dropped': 1802, '18': 1803, 'tw': 1804, 'row': 1805, 'applications': 1806, 'octave': 1807, 'validation': 1808, 'epsilon': 1809, 'confusing': 1810, '90': 1811, 'coefficient': 1812, 'corrected': 1813, '\\xa0so': 1814, 'rt': 1815, \"won't\": 1816, '31': 1817, '\\x97': 1818, 'contain': 1819, 'experimental': 1820, '\\xa0the': 1821, '0100': 1822, 'coefficients': 1823, 'hw': 1824, 'derived': 1825, 'ci': 1826, 'deviation': 1827, 'root': 1828, 'hypotheses': 1829, 'h0': 1830, '384': 1831, '096': 1832, 'pdt': 1833, '024': 1834, '2024': 1835, '1814': 1836, '96': 1837, 'checkbox': 1838, 'distributions': 1839, 'contents': 1840, 'addr': 1841, '\\xa0\\xa0': 1842, '\\xa0tar': 1843, 'invalid': 1844, 'multiprocessor': 1845, 'victim': 1846, 'x86': 1847, 'queue': 1848, 'cycles': 1849, 'alu': 1850, 'bricks': 1851, 'modules': 1852, 'chop': 1853, 'partially': 1854, 'exclusive': 1855, 'kb': 1856, 'offset': 1857, 'base': 1858, 'cylinder': 1859, 'pulley': 1860, 'studying': 1861, 'quizzes': 1862, 'geology': 1863, 'track': 1864, 'button': 1865, 'advice': 1866, 'sources': 1867, 'delay': 1868, 'sulfur': 1869, 'dioxide': 1870, 'appeared': 1871, 'origin': 1872, 'account': 1873, 'conditions': 1874, 'standing': 1875, 'copied': 1876, 'shift': 1877, 'sun': 1878, 'vertical': 1879, 'horizontal': 1880, 'anymore': 1881, 'url': 1882, 'database': 1883, 'familiar': 1884, 'closely': 1885, 'conversion': 1886, '2003': 1887, 'acid': 1888, 'theta': 1889, 'pi': 1890, 've': 1891, 'organisms': 1892, 'prefer': 1893, 'constantly': 1894, 'strand': 1895, 'green': 1896, 'range': 1897, 'window': 1898, 'tab': 1899, 'description': 1900, 'longer': 1901, 'offering': 1902, 'browser': 1903, 'drive': 1904, '80': 1905, 'web': 1906, 'wayne': 1907, 'followed': 1908, 'os': 1909, 'interface': 1910, 'identical': 1911, 'humans': 1912, 'depending': 1913, 'systems': 1914, 'affected': 1915, 'exercise': 1916, 'settings': 1917, 'ps': 1918, 'closest': 1919, 'linda': 1920, 'broken': 1921, 'possibility': 1922, 'unclear': 1923, 'clicking': 1924, 'matches': 1925, 'confidence': 1926, 'seconds': 1927, 'actual': 1928, \"here's\": 1929, 'terminated': 1930, 'mafft': 1931, 'charts': 1932, 'jalview': 1933, 'menu': 1934, 'edit': 1935, 'notepad': 1936, 'remove': 1937, 'performing': 1938, 'listed': 1939, '70': 1940, 'fairly': 1941, 'night': 1942, 'member': 1943, 'listening': 1944, 'community': 1945, 'html': 1946, 'deeply': 1947, 'traffic': 1948, 'ii': 1949, 'pair': 1950, 'verify': 1951, 'incoming': 1952, 'grasp': 1953, 'counted': 1954, 'v1': 1955, 'devices': 1956, 'area': 1957, 'band': 1958, 'engineering': 1959, 'mathematics': 1960, 'calculus': 1961, 'algebra': 1962, 'ad': 1963, 'temp': 1964, 'curve': 1965, 'predict': 1966, 'sensitivity': 1967, 'quantity': 1968, 'motions': 1969, 'doubling': 1970, 'approach': 1971, 'answered': 1972, 'telling': 1973, 'lapse': 1974, 'moist': 1975, '279': 1976, 'indicates': 1977, 'lesson': 1978, '\\x80\\x94': 1979, 'determining': 1980, 'properly': 1981, 'tropopause': 1982, 'properties': 1983, 'downwards': 1984, 'varying': 1985, 'switch': 1986, 'absorb': 1987, 'complex': 1988, 'atoms': 1989, 'requires': 1990, 'uv': 1991, 'mentioning': 1992, 'favorite': 1993, 'various': 1994, 'skeptics': 1995, 'extreme': 1996, 'informed': 1997, 'skeptic': 1998, 'segment': 1999, 'pane': 2000, 'co': 2001, 'o2': 2002, 'ahead': 2003, 'push': 2004, 'newton': 2005, 'cm': 2006, 'exert': 2007, 'arbitrary': 2008, 'rules': 2009, 'established': 2010, 'spin': 2011, 'thumb': 2012, 'dear': 2013, 'regard': 2014, \"newton's\": 2015, 'external': 2016, 'cars': 2017, 'ramp': 2018, 'decrease': 2019, 'maintain': 2020, 'stored': 2021, 'transferred': 2022, 'transfer': 2023, 'experienced': 2024, 'exerted': 2025, 'applying': 2026, 'impulse': 2027, 'pulls': 2028, 'thereby': 2029, 'backwards': 2030, 'cg': 2031, 'cyclist': 2032, 'sliding': 2033, 'cook': 2034, 'cooking': 2035, 'puts': 2036, 'warm': 2037, 'cooked': 2038, 'recovered': 2039, 'photography': 2040, 'simultaneously': 2041, 'toy': 2042, 'falls': 2043, 'package': 2044, 'parts': 2045, 'purposes': 2046, 'measure': 2047, 'huge': 2048, 'remains': 2049, 'knife': 2050, 'executed': 2051, 'truly': 2052, 'guessing': 2053, 'crash': 2054, 'onto': 2055, 'robert': 2056, 'memories': 2057, 'mostly': 2058, 'midnight\\x80\\x9d': 2059, 'period': 2060, 'develop': 2061, 'aspects': 2062, 'director': 2063, 'involves': 2064, 'guy': 2065, 'misunderstanding': 2066, 'feels': 2067, 'sound': 2068, 'fetched': 2069, 'mr': 2070, 'mrs': 2071, 'centre': 2072, 'drama': 2073, 'affection': 2074, 'elements': 2075, 'audiences': 2076, 'enjoy': 2077, '1962': 2078, 'recommend': 2079, 'introduced': 2080, 'ordinary': 2081, 'foreign': 2082, 'la': 2083, 'joy': 2084, 'thinks': 2085, 'odd': 2086, 'basinger': 2087, 'homicide': 2088, 'lina': 2089, 'serious': 2090, 'alternative': 2091, 'paris': 2092, 'expressed': 2093, 'reasons': 2094, 'trust': 2095, 'regardless': 2096, 'intended': 2097, 'picasso': 2098, 'reflecting': 2099, 'agency': 2100, 'solved': 2101, 'childhood': 2102, 'institution': 2103, 'defining': 2104, 'essence': 2105, 'plays': 2106, 'dramatic': 2107, 'entirely': 2108, 'constitute': 2109, 'attraction': 2110, 'father': 2111, 'murder': 2112, 'anne': 2113, 'hanks': 2114, 'meg': 2115, 'ryan': 2116, 'becoming': 2117, 'busy': 2118, 'children': 2119, 'realize': 2120, 'reynolds': 2121, 'fisher': 2122, 'daughter': 2123, 'eventually': 2124, 'kathleen': 2125, 'douglas': 2126, 'believable': 2127, 'speech': 2128, 'struggling': 2129, 'mil': 2130, 'dil': 2131, 'allows': 2132, 'sees': 2133, 'initially': 2134, 'june': 2135, 'walked': 2136, 'appropriating': 2137, 'photographer': 2138, 'riot': 2139, 'quote': 2140, 'revealed': 2141, 'auction': 2142, 'announcement': 2143, 'michel': 2144, 'extent': 2145, 'manhattan': 2146, 'visit': 2147, 'quality': 2148, 'beauty': 2149, 'black': 2150, 'signs': 2151, 'homosexual': 2152, 'relief': 2153, 'attempt': 2154, 'began': 2155, 'rolling': 2156, 'jagger': 2157, 'zipper': 2158, \"would've\": 2159, 'unfortunately': 2160, 'caused': 2161, 'sitting': 2162, 'replying': 2163, 'covers': 2164, 'records': 2165, 'commenting': 2166, 'devout': 2167, 'challenging': 2168, 'religious': 2169, 'entertainment': 2170, 'lack': 2171, 'harm': 2172, 'erotic': 2173, 'prints': 2174, 'reconciled': 2175, 'slightly': 2176, 'recognition': 2177, 'claimed': 2178, 'logical': 2179, 'brigid': 2180, 'berlin': 2181, 'fremont': 2182, '1969': 2183, 'possession': 2184, 'references': 2185, 'comfortable': 2186, 'jed': 2187, '45': 2188, 'ended': 2189, 'commodity': 2190, 'grim': 2191, 'forecasts': 2192, 'costs': 2193, 'tag': 2194, 'wwii': 2195, 'museums': 2196, 'sell': 2197, '20th': 2198, 'analogous': 2199, 'owner': 2200, 'lived': 2201, 'behavior': 2202, 'poverty': 2203, 'school': 2204, 'mickey': 2205, 'venice': 2206, 'collected': 2207, 'news': 2208, 'special': 2209, 'thrilled': 2210, 'gogh': 2211, \"d'offay\": 2212, 'political': 2213, 'distinction': 2214, 'wealthy': 2215, 'regarded': 2216, 'creator': 2217, 'holds': 2218, 'receive': 2219, 'growing': 2220, 'room': 2221, 'dot': 2222, 'fourth': 2223, 'claim': 2224, 'produce': 2225, 'commissioned': 2226, 'viewers': 2227, 'repeating': 2228, 'perform': 2229, 'unfamiliar': 2230, 'themselves': 2231, 'meaningless': 2232, 'glyn': 2233, 'davis': 2234, 'discuss': 2235, 'producing': 2236, 'popularity': 2237, 'magazines': 2238, 'electric': 2239, 'chair': 2240, 'active': 2241, 'pittsburgh': 2242, 'timerefpm': 2243, 'tiny': 2244, 'eight': 2245, 'explored': 2246, 'party': 2247, 'lives': 2248, 'silent': 2249, 'reel': 2250, 'versa': 2251, 'challenge': 2252, 'decision': 2253, 'adjusted': 2254, 'alternate': 2255, 'enter': 2256, 'im': 2257, 'ponder': 2258, 'surprised': 2259, 'reproduction': 2260, 'singular': 2261, 'chosen': 2262, 'infinitely': 2263, 'warhola': 2264, 'nursing': 2265, 'orders': 2266, 'disease': 2267, 'books': 2268, 'poster': 2269, 'persona': 2270, 'collage': 2271, 'language': 2272, 'elvis': 2273, 'cindy': 2274, 'reckon': 2275, 'btw': 2276, 'associated': 2277, 'connection': 2278, 'sequential': 2279, 'funny': 2280, 'fundamental': 2281, 'speak': 2282, 'talent': 2283, 'everybody': 2284, 'exploring': 2285, 'introductory': 2286, 'knowing': 2287, 'lens': 2288, 'basic': 2289, 'teacher': 2290, 'engaging': 2291, 'review': 2292, 'lecturer': 2293, 'extra': 2294, 'curator': 2295, 'observed': 2296, 'educated': 2297, \"art'\": 2298, 'hands': 2299, 'draw': 2300, 'connected': 2301, 'instances': 2302, 'asks': 2303, \"we'll\": 2304, 'spontaneous': 2305, 'processes': 2306, 'formal': 2307, 'multi': 2308, 'mechanism': 2309, 'observation': 2310, 'project': 2311, 'raises': 2312, 'cross': 2313, 'persists': 2314, 'administrator': 2315, 'h3': 2316, 'generously': 2317, 'misleading': 2318, 'pre': 2319, 'initializing': 2320, 'sharing': 2321, 'prevent': 2322, 'gradient': 2323, 'stupid': 2324, 'hmm': 2325, 'mechanics': 2326, 'covered': 2327, 'argument': 2328, 'transitions': 2329, 'regular': 2330, 'assumptions': 2331, 'energies': 2332, 'require': 2333, 'diverge': 2334, 'runs': 2335, 'pa4': 2336, 'explanations': 2337, 'spurious': 2338, 'minima': 2339, '43': 2340, 'belief': 2341, 'subtitles': 2342, 'stochastic': 2343, 'entire': 2344, 'uniform': 2345, 'trained': 2346, 'advantages': 2347, 'typically': 2348, 'automata': 2349, 'circuit': 2350, 'tasks': 2351, 'timelines': 2352, 'potentially': 2353, 'pass': 2354, 'element': 2355, 'initialized': 2356, 'pointed': 2357, 'latex': 2358, 'recipe': 2359, 'combining': 2360, 'penalty': 2361, 'obtained': 2362, 'expand': 2363, 'tijmen': 2364, 'waiting': 2365, 'remembering': 2366, 'types': 2367, 'optimum': 2368, 'triangle': 2369, 'shed': 2370, 'dinitrogen': 2371, 'tetroxide': 2372, '\\xa0it': 2373, 'molk': 2374, '300': 2375, 'q15': 2376, 'causal': 2377, 'reported': 2378, '95': 2379, 'sunday': 2380, 'zeger': 2381, '\\xa0in': 2382, 'ports': 2383, 'bus': 2384, 'walker': 2385, 'yadav': 2386, 'fault': 2387, 'reload': 2388, 'execution': 2389, 'l2': 2390, 'gpu': 2391, 'schedule': 2392, 'pointer': 2393, 'modified': 2394, 'arm': 2395, 'scoreboard': 2396, 'reorder': 2397, 'strobe': 2398, 'signal': 2399, 'r7': 2400, 'organization': 2401, 'flip': 2402, 'flops': 2403, 'operations': 2404, 'exceptions': 2405, 'addiu': 2406, 'r4': 2407, 'multicycle': 2408, 'unpipelined': 2409, 'bytes': 2410, 'module': 2411, 'refrigerator': 2412, 'chopped': 2413, 'deadlock': 2414, '63': 2415, 'leaf': 2416, '51': 2417, 'r8': 2418, \"'267\": 2419, 'slack': 2420, 'si': 2421, 'syllabus': 2422, 'grading': 2423, 'peer': 2424, 'reviewed': 2425, 'uploaded': 2426, 'tedious': 2427, 'uploading': 2428, 'email': 2429, 'willing': 2430, 'attached': 2431, 'individually': 2432, 'pic': 2433, 'grammar': 2434, '88': 2435, 'lasted': 2436, 'enclose': 2437, 'disappointing': 2438, 'limit': 2439, 'marketing': 2440, 'resource': 2441, 'evidence': 2442, 'accessible': 2443, 'pace': 2444, 'date': 2445, 'radius': 2446, 'r1': 2447, 'combine': 2448, 'poles': 2449, 'equator': 2450, 'volcano': 2451, 'places': 2452, 'crust': 2453, 'shortening': 2454, 'recorded': 2455, 'leading': 2456, 'muscle': 2457, 'provart': 2458, 'closer': 2459, 'peers': 2460, 'providing': 2461, 'innovative': 2462, 'informative': 2463, 'software': 2464, 'eg': 2465, 'constructed': 2466, '28': 2467, 'sampled': 2468, 'defines': 2469, 'parsimony': 2470, 'internal': 2471, 'substitutions': 2472, 'selective': 2473, 'protein': 2474, 'mutation': 2475, 'resistance': 2476, 'variation': 2477, 'amino': 2478, 'inconsistency': 2479, 'contradiction': 2480, 'balancing': 2481, 'whilst': 2482, 'tend': 2483, 'drift': 2484, 'exposure': 2485, \"5'\": 2486, 'simplification': 2487, 'submitted': 2488, 'bug': 2489, 'pax6': 2490, 'gene': 2491, 'panel': 2492, 'orthologous': 2493, '183': 2494, 'indicated': 2495, 'coding': 2496, 'connecting': 2497, 'configure': 2498, 'handles': 2499, 'lucky': 2500, 'inclined': 2501, \"instructor's\": 2502, 'oracle': 2503, 'month': 2504, 'technical': 2505, 'mini': 2506, 'avail': 2507, 'card': 2508, 'specs': 2509, 'mice': 2510, 'toggle': 2511, 'item': 2512, '174': 2513, 'answering': 2514, 'coloured': 2515, 'zeros': 2516, 'purple': 2517, '7e': 2518, '178': 2519, 'confirmed': 2520, 'al': 2521, 'hits': 2522, 'gain': 2523, 'presenting': 2524, 'outputs': 2525, 'quizz': 2526, 'databases': 2527, 'concerns': 2528, 'performed': 2529, 'penalties': 2530, 'smth': 2531, 'warning': 2532, 'anchor': 2533, '639': 2534, '414': 2535, 'exported': 2536, 'suggestions': 2537, 'unaligned': 2538, 'fasta': 2539, 'command': 2540, 'lab3': 2541, '\\x80': 2542, 'arleigh': 2543, 'manually': 2544, 'andrew': 2545, 'vista': 2546, 'press': 2547, '\\xa0once': 2548, 'selected': 2549, 'significance': 2550, 'characteristic': 2551, 'sites': 2552, '60': 2553, 'marinus': 2554, 'corresponds': 2555, 'linked': 2556, 'generated': 2557, 'phylogeny': 2558, 'hypertension': 2559, 'smoking': 2560, 'diabetes': 2561, 'plausible': 2562, 'blame': 2563, 'pregnancy': 2564, 'tries': 2565, 'carries': 2566, 'vocabulary': 2567, 'medical': 2568, 'native': 2569, 'speakers': 2570, 'invited': 2571, 'packet': 2572, 'distributive': 2573, 'formulas': 2574, 'breaks': 2575, 'v2': 2576, 'merely': 2577, 'q1': 2578, 'cdma': 2579, '2g': 2580, '3g': 2581, 'speeds': 2582, 'areas': 2583, '1g': 2584, 'algorithms': 2585, 'usage': 2586, '800mhz': 2587, 'ee': 2588, 'wk': 2589, '800': 2590, 'graph': 2591, 'hockey': 2592, 'stick': 2593, 'likewise': 2594, '350': 2595, 'controls': 2596, 'absorption': 2597, 'ocean': 2598, 'assumes': 2599, 'geometric': 2600, 'growth': 2601, 'limited': 2602, '2c': 2603, 'additional': 2604, 'originally': 2605, '10x': 2606, 'gotten': 2607, 'scenario': 2608, 'carbon': 2609, 'emissions': 2610, 'modeling': 2611, 'visualize': 2612, 'discussing': 2613, 'methane': 2614, 'lessens': 2615, '227': 2616, 'dry': 2617, 'radiated': 2618, 'follows': 2619, 'reduces': 2620, 'adiabat': 2621, 'teach': 2622, 'venus': 2623, 'stages': 2624, 'development': 2625, 'flows': 2626, 'freely': 2627, 'profile': 2628, 'raising': 2629, 'o3': 2630, 'ghgs': 2631, 'radiate': 2632, 'definite': 2633, 'structure': 2634, '': 2635, 'strength': 2636, 'heated': 2637, 'plate': 2638, 'claims': 2639, 'violation': 2640, 'nevertheless': 2641, 'cold': 2642, 'attack': 2643, 'watts': 2644, 'anthony': 2645, 'sanity': 2646, 'kinda': 2647, 'escapes': 2648, 'bounce': 2649, 'ir': 2650, 'formed': 2651, 'h2o': 2652, 'wait': 2653, 'violate': 2654, 'smooth': 2655, '30': 2656, 'rough': 2657, 'terrain': 2658, 'exerts': 2659, 'riders': 2660, 'dimensions': 2661, 'communication': 2662, 'screw': 2663, 'clockwise': 2664, 'moves': 2665, 'wheels': 2666, 'experiencing': 2667, 'upwards': 2668, 'angle': 2669, 'fellow': 2670, 'advise': 2671, 'colleague': 2672, 'skydiver': 2673, 'rotates': 2674, 'obeying': 2675, 'allowing': 2676, 'fair': 2677, 'rubber': 2678, \"wagon's\": 2679, 'ish': 2680, 'accelerated': 2681, 'deceleration': 2682, 'decreases': 2683, 'forget': 2684, 'bloomfield': 2685, 'pull': 2686, 'pedal': 2687, 'turns': 2688, 'experiences': 2689, 'weigh': 2690, 'rotated': 2691, 'bearing': 2692, 'stronger': 2693, 'bigger': 2694, 'overcome': 2695, 'generally': 2696, 'fire': 2697, 'staying': 2698, 'counts': 2699, 'provides': 2700, 'respected': 2701, 'sir': 2702, 'travel': 2703, 'trick': 2704, 'perfectly': 2705, 'lewis': 2706, \"wolpert's\": 2707, 'unnatural': 2708, 'ping': 2709, 'pong': 2710, 'straight': 2711, 'bet': 2712, 'impressive': 2713, 'puzzle': 2714, 'talks': 2715, 'directions': 2716, 'universal': 2717, \"object's\": 2718, 'stuff': 2719, 'damage': 2720, 'acts': 2721, 'apple': 2722, 'quickly': 2723, 'removing': 2724, 'conservation': 2725, '\\xa0can': 2726, 'masked': 2727, 'interactions': 2728, 'kinetic': 2729, 'component': 2730, 'jane': 2731, 'fonda': 2732, 'redford': 2733, 'nm': 2734, 'flmg': 2735, 'sleeping': 2736, 'partner': 2737, 'breaking': 2738, 'waves': 2739, 'protagonists': 2740, '2013': 2741, 'talked': 2742, '\\x80\\x93': 2743, '3rd': 2744, 'emotional': 2745, 'spouse': 2746, 'encounter': 2747, 'difficult': 2748, 'disturbing': 2749, 'brad': 2750, 'pitt': 2751, 'angelina': 2752, 'jolie': 2753, 'excitement': 2754, '1968': 2755, \"'the\": 2756, 'henry': 2757, 'court': 2758, 'comedy': 2759, 'continue': 2760, 'clip': 2761, 'violence': 2762, 'netflix': 2763, 'scenes': 2764, 'ingmar': 2765, 'ha': 2766, 'chalte': 2767, 'amazed': 2768, 'girl': 2769, 'sins': 2770, 'marriages': 2771, 'neither': 2772, '6th': 2773, 'quiet': 2774, 'major': 2775, 'responses': 2776, 'johnnie': 2777, 'suicide': 2778, 'doubts': 2779, '1960s': 2780, 'classmates': 2781, 'impression': 2782, 'stayed': 2783, \"she's\": 2784, 'alternatively': 2785, 'insisted': 2786, 'accept': 2787, 'murderer': 2788, 'kill': 2789, 'exit': 2790, 'investigate': 2791, 'expecting': 2792, 'emphasized': 2793, 'strongly': 2794, 'beliefs': 2795, 'carefully': 2796, 'designed': 2797, 'overt': 2798, 'tasked': 2799, 'shape': 2800, 'william': 2801, 'powell': 2802, 'myrna': 2803, 'loy': 2804, 'happily': 2805, 'anniversary': 2806, 'plain': 2807, 'eat': 2808, 'parents': 2809, 'indian': 2810, 'village': 2811, 'faith': 2812, '1963': 2813, 'housewife': 2814, 'failed': 2815, 'titles': 2816, 'undergo': 2817, 'kramer': 2818, 'bridges': 2819, 'road': 2820, 'raise': 2821, 'intentions': 2822, 'august': 2823, 'golden': 2824, 'generations': 2825, 'popped': 2826, 'ingrid': 2827, 'charles': 2828, 'boyer': 2829, \"basinger's\": 2830, 'plot': 2831, 'brother': 2832, 'carried': 2833, 'magic': 2834, 'debbie': 2835, 'doris': 2836, 'star': 2837, 'liz': 2838, 'taylor': 2839, 'woody': 2840, 'allen': 2841, 'cosby': 2842, 'african': 2843, 'queen': 2844, 'stone': 2845, 'turner': 2846, 'michael': 2847, 'continued': 2848, 'anyways': 2849, 'pattern': 2850, 'stream': 2851, 'readings': 2852, 'focus': 2853, 'stewart': 2854, 'son': 2855, 'remind': 2856, 'luxury': 2857, 'clothing': 2858, 'opportunity': 2859, 'safely': 2860, 'contemplate': 2861, 'boundaries': 2862, 'wild': 2863, 'beating': 2864, 'dominated': 2865, 'kisses': 2866, 'communicate': 2867, 'coal': 2868, \"lynn's\": 2869, 'tommy': 2870, 'cash': 2871, 'lady': 2872, 'focusing': 2873, 'construct': 2874, 'sold': 2875, 'flowers': 2876, 'lifted': 2877, 'race': 2878, 'emotions': 2879, 'remembered': 2880, 'terrible': 2881, 'truth': 2882, 'inequality': 2883, 'rights': 2884, 'ability': 2885, 'jackie': 2886, '17': 2887, \"monroe's\": 2888, 'fades': 2889, 'intend': 2890, 'ubiquitous': 2891, 'breeskin': 2892, 'stands': 2893, 'birth': 2894, 'revolution': 2895, 'everywhere': 2896, 'sigh': 2897, \"stones'\": 2898, 'sticky': 2899, 'fingers': 2900, 'mick': 2901, 'remark': 2902, 'playful': 2903, 'voyeuristic': 2904, 'packed': 2905, 'hired': 2906, 'promotional': 2907, 'basie': 2908, 'corporate': 2909, 'controversial': 2910, 'stones': 2911, 'treating': 2912, 'treated': 2913, 'delivered': 2914, 'barbarella': 2915, 'confident': 2916, 'stripped': 2917, 'graphic': 2918, 'historically': 2919, 'china': 2920, 'pornographic': 2921, 'fixation': 2922, 'featured': 2923, 'creativity': 2924, 'outsider': 2925, 'dress': 2926, 'religion': 2927, 'publicity': 2928, 'identity': 2929, 'forgotten': 2930, 'forays': 2931, 'conjecture': 2932, 'speculate': 2933, 'queer': 2934, 'makers': 2935, 'drawings': 2936, 'nudes': 2937, 'rejected': 2938, 'interviews': 2939, 'publications': 2940, 'peace': 2941, 'feelings': 2942, 'men': 2943, 'soul': 2944, 'despite': 2945, 'sad': 2946, 'extract': 2947, 'amazing': 2948, 'shallow': 2949, 'insights': 2950, 'killed': 2951, '1974': 2952, 'superstars': 2953, 'laid': 2954, 'lucrative': 2955, 'sole': 2956, 'sales': 2957, 'loving': 2958, 'wasting': 2959, 'aw': 2960, 'collaboration': 2961, 'johnson': 2962, 'flight': 2963, 'vision': 2964, 'permanently': 2965, 'associate': 2966, 'collective': 2967, 'mirror': 2968, 'dollar': 2969, 'printing': 2970, 'soaring': 2971, 'contribute': 2972, 'smart': 2973, 'stratification': 2974, 'paying': 2975, 'bragging': 2976, 'collectors': 2977, 'exhibitions': 2978, 'witness': 2979, 'express': 2980, 'likes': 2981, 'invest': 2982, 'rich': 2983, 'depression': 2984, 'spot': 2985, 'hoarding': 2986, 'schulhofs': 2987, 'chairman': 2988, 'sony': 2989, 'europe': 2990, 'grew': 2991, 'valuable': 2992, 'million': 2993, 'alive': 2994, 'heirs': 2995, 'tax': 2996, 'gift': 2997, 'donating': 2998, \"schulhof's\": 2999, 'fantastic': 3000, 'earning': 3001, 'managing': 3002, 'schulhof': 3003, 'guggenheims': 3004, 'wise': 3005, 'plane': 3006, 'eccentric': 3007, \"he'd\": 3008, 'thousands': 3009, 'capture': 3010, 'rockwell': 3011, 'hearing': 3012, 'relevant': 3013, 'accurately': 3014, 'explicit': 3015, 'advised': 3016, 'fashion': 3017, 'disagree': 3018, 'renaissance': 3019, 'painter': 3020, 'inspire': 3021, 'silk': 3022, 'facial': 3023, 'sculpture': 3024, 'saint': 3025, 'theresa': 3026, 'galleries': 3027, \"hasn't\": 3028, 'eye': 3029, 'coca': 3030, 'items': 3031, 'sustain': 3032, 'silly': 3033, 'reflected': 3034, 'tangible': 3035, 'soared': 3036, 'anecdote': 3037, 'touch': 3038, 'instant': 3039, 'consumer': 3040, 'commissions': 3041, 'ans': 3042, 'costly': 3043, 'emergence': 3044, 'rapidly': 3045, 'asian': 3046, 'markets': 3047, \"china's\": 3048, 'subsequent': 3049, 'immediately': 3050, 'decades': 3051, 'russian': 3052, 'india': 3053, 'salvador': 3054, 'dali': 3055, 'rope': 3056, \"aw's\": 3057, 'incomplete': 3058, 'seriously': 3059, 'personally': 3060, 'technically': 3061, 'brilliant': 3062, 'infinite': 3063, 'unexplored': 3064, 'exchange': 3065, 'wrbican': 3066, 'hiring': 3067, 'managed': 3068, 'valued': 3069, 'screenprints': 3070, 'reception': 3071, 'thomas': 3072, 'vanity': 3073, 'partly': 3074, 'boot': 3075, \"rockwell's\": 3076, 'compares': 3077, 'critical': 3078, 'adult': 3079, 'differently': 3080, 'threshold': 3081, 'automatic': 3082, \"hadn't\": 3083, 'conscious': 3084, \"viewer's\": 3085, 'meanings': 3086, 'st': 3087, 'listen': 3088, 'morning': 3089, 'refer': 3090, 'fee': 3091, 'asleep': 3092, 'pick': 3093, 'expressions': 3094, 'hell': 3095, 'realization': 3096, 'leave': 3097, 'understandable': 3098, 'activity': 3099, 'accidents': 3100, 'faced': 3101, 'task': 3102, 'frames': 3103, 'mesmerising': 3104, 'filmed': 3105, 'convinced': 3106, 'fascinated': 3107, \"viola's\": 3108, \"hollywood's\": 3109, 'colonized': 3110, 'extended': 3111, 'traditional': 3112, 'moments': 3113, 'posing': 3114, 'intriguing': 3115, 'sitter': 3116, 'sedgwick': 3117, 'passing': 3118, 'domesticated': 3119, 'soap': 3120, 'radio': 3121, 'dare': 3122, 'walter': 3123, \"benjamin's\": 3124, 'mechanical': 3125, 'digital': 3126, 'essential': 3127, 'avoided': 3128, 'stars': 3129, '02': 3130, 'distributed': 3131, 'appropiation': 3132, 'domain': 3133, '2d': 3134, 'includes': 3135, 'behaviour': 3136, 'national': 3137, 'seeking': 3138, 'fields': 3139, 'wears': 3140, 'outfits': 3141, 'creating': 3142, 'shepard': 3143, 'fairey': 3144, 'stezaker': 3145, 'appropriates': 3146, 'photos': 3147, 'critically': 3148, 'surrealism': 3149, 'appropriation': 3150, 'worship': 3151, 'banksy': 3152, 'creation': 3153, 'exhibition': 3154, 'mainstream': 3155, 'glad': 3156, 'emerging': 3157, 'dream': 3158, 'marylin': 3159, 'happening': 3160, 'coin': 3161, 'captivating': 3162, 'heads': 3163, 'alas': 3164, 'complaining': 3165, 'sue': 3166, 'conceptualization': 3167, 'college': 3168, 'entitled': 3169, 'unwatchable': 3170, 'adls': 3171, 'provocative': 3172, 'presume': 3173, 'felt': 3174, 'replied': 3175, 'assistant': 3176, 'academics': 3177, 'satisfies': 3178, 'limits': 3179, 'treatment': 3180, 'finished': 3181, 'explains': 3182, 'reflect': 3183, 'irrelevant': 3184, 'tan': 3185, 'brings': 3186, 'hey': 3187, 'campbells': 3188, 'edges': 3189, 'portraiture': 3190, 'discrete': 3191, 'separated': 3192, 'degradation': 3193, 'opposite': 3194, 'imperfect': 3195, 'origins': 3196, 'advertising': 3197, 'literature': 3198, 'unattractive': 3199, 'evaluation': 3200, 'acute': 3201, 'observers': 3202, 'observational': 3203, 'key': 3204, 'interpret': 3205, 'everyday': 3206, 'marc': 3207, 'raised': 3208, 'pointing': 3209, 'techniques': 3210, 'neuron': 3211, 'softmax': 3212, 'entropy': 3213, 'region': 3214, 'hyper': 3215, 'false': 3216, 'perceptron': 3217, 'hg': 3218, 'sub': 3219, 'extends': 3220, 'sentence': 3221, 'worded': 3222, 'wording': 3223, '15f': 3224, 'referring': 3225, 'nn': 3226, 'rlu': 3227, 'gradients': 3228, 'bayesian': 3229, 'regularization': 3230, 'absps': 3231, 'stable': 3232, 'updating': 3233, 'respectively': 3234, 'q': 3235, 'cd': 3236, 'satisfied': 3237, 'monte': 3238, 'carlo': 3239, 'denote': 3240, 'flaw': 3241, 'depend': 3242, 'dmitry': 3243, 'divided': 3244, 'partition': 3245, 'ij': 3246, 'suggesting': 3247, \"boltzmann's\": 3248, 'edited': 3249, 'transitioning': 3250, 'hardly': 3251, 'converge': 3252, 'mathematically': 3253, 'hint': 3254, 'datacases': 3255, 'estimation': 3256, 'ignoring': 3257, 'averaging': 3258, 'settling': 3259, 'settled': 3260, 'guys': 3261, '66': 3262, 'encoders': 3263, 'tuning': 3264, 'ta': 3265, 'anomaly': 3266, 'detection': 3267, 'built': 3268, 'activation': 3269, 'intentional': 3270, 'sigmoid': 3271, 'fitting': 3272, 'unsupervised': 3273, 'mode': 3274, 'supervised': 3275, 'conditional': 3276, 'enforced': 3277, 'functions': 3278, 'replace': 3279, 'coordinates': 3280, 'mathematical': 3281, \"wilson's\": 3282, 'kitchen': 3283, 'corresponding': 3284, 'rescale': 3285, 'hf': 3286, 'convergence': 3287, 'approximations': 3288, 'inverse': 3289, 'feedforward': 3290, 'wondered': 3291, 'unfolded': 3292, 'dimension': 3293, 'analogy': 3294, 'diagrams': 3295, 'author': 3296, 'fan': 3297, 'respond': 3298, 'achieve': 3299, 'implemented': 3300, 'prediction': 3301, 'affect': 3302, 'simpler': 3303, 'introduce': 3304, 'inefficient': 3305, 'frustrating': 3306, 'hm': 3307, 'researchers': 3308, 'edge': 3309, 'prop': 3310, 'adjacent': 3311, 'matrices': 3312, 'matha': 3313, 'tu': 3314, \"b'\": 3315, \"a'\": 3316, 'resort': 3317, 'tinymce': 3318, 'plugin': 3319, 'supports': 3320, 'echo': 3321, 'translation': 3322, 'grows': 3323, 'infeasible': 3324, '256': 3325, '137': 3326, '139': 3327, 'checking': 3328, 'bayes': 3329, 'penalize': 3330, 'equals': 3331, 'recoded': 3332, '784': 3333, '2495': 3334, 'num': 3335, 'rocket': 3336, 'balanced': 3337, \"charlie's\": 3338, 'subtraction': 3339, 'pooling': 3340, 'hints': 3341, 'avoid': 3342, 'explicitly': 3343, '5b': 3344, 'rotate': 3345, 'elementary': 3346, 'plug': 3347, 'graphing': 3348, '\\xa0or': 3349, 'regression': 3350, 'subtract': 3351, '\\xa0also': 3352, 'rates': 3353, 'objectives': 3354, 'debate': 3355, 'measuring': 3356, '\\xa0this': 3357, 'bp': 3358, 'chemists': 3359, 'mol': 3360, '314': 3361, 'explaining': 3362, 'ap': 3363, 'scores': 3364, '0016': 3365, '01': 3366, 'melissa': 3367, 'denominator': 3368, 'fractions': 3369, 'quantities': 3370, 'printed': 3371, 'peter': 3372, 'integral': 3373, 'maps': 3374, 'dont': 3375, 'distinguished': 3376, 'stats': 3377, 'nonetheless': 3378, 'clustered': 3379, 'spend': 3380, 'uncertainty': 3381, \"1's\": 3382, \"2's\": 3383, 'persons': 3384, 'approximately': 3385, 'reasoned': 3386, \"bayes'\": 3387, '98': 3388, 'welcome': 3389, 'usha': 3390, '19': 3391, 'consistent': 3392, 'login': 3393, 'gmt': 3394, '1b': 3395, 'pm': 3396, '1a': 3397, 'easiest': 3398, 'stdev': 3399, '536': 3400, '907': 3401, '814': 3402, '72': 3403, '116': 3404, '2931': 3405, '209': 3406, '3839': 3407, 'interval': 3408, 'rated': 3409, 'incarceration': 3410, 'intervention': 3411, 'choices': 3412, 'roughly': 3413, 'expenditure': 3414, '75': 3415, '34': 3416, 'landscaping': 3417, 'cubic': 3418, '68': 3419, 'br': 3420, 'timing': 3421, 'f\\xa0': 3422, 'cond': 3423, 'simplest': 3424, 'icache': 3425, 'scalar': 3426, 'circuitry': 3427, 'operation': 3428, 'snoopy': 3429, 'engine': 3430, 'misses': 3431, 'disk': 3432, 'latency': 3433, 'warp': 3434, 'cuda': 3435, 'pcs': 3436, 'buffers': 3437, 'allocate': 3438, 'evicted': 3439, 'slower': 3440, 'mips': 3441, 'pending': 3442, 'promised': 3443, 'frontend': 3444, '\\xa0if': 3445, '\\xa0however': 3446, 'strobing': 3447, 'architecture': 3448, 'ws': 3449, 'selectors': 3450, 'structural': 3451, 'lw': 3452, 'deck': 3453, 'r12': 3454, 'r11': 3455, 'dram': 3456, 'sram': 3457, 'confuse': 3458, 'core': 3459, 'chip': 3460, 'vegetables': 3461, 'chopping': 3462, 'corners': 3463, 'mix': 3464, 'bowl': 3465, 'fridge': 3466, \"nt'\": 3467, '4100': 3468, 'msi': 3469, 'reserved': 3470, 'generic': 3471, 'rs': 3472, 'rc': 3473, 'indexes': 3474, 'pages': 3475, 'allocated': 3476, 'pte': 3477, 'ps4': 3478, \"'case\": 3479, 'bypass': 3480, 'x0': 3481, 'r9': 3482, '\\xa0f': 3483, 'x1': 3484, 'cpi': 3485, '\\xa0not': 3486, 'r20': 3487, '2752': 3488, '68288': 3489, '128': 3490, \"'f1'\": 3491, \"'n1\": 3492, \"889n'\": 3493, \"'f1max'\": 3494, \"'f1max\": 3495, \"267n'\": 3496, \"889'\": 3497, 'cord': 3498, 'wrapped': 3499, 'rolled': 3500, 'coiled': 3501, 'com': 3502, 'gm': 3503, 'nonzero': 3504, 'mile': 3505, 'slugs': 3506, 'imperial': 3507, 'evolution': 3508, 'announced': 3509, 'essays': 3510, 'localities': 3511, 'shame': 3512, 'electronic': 3513, 'unreachable': 3514, 'policy': 3515, 'you\\x80\\x99d': 3516, 'warned': 3517, 'mine': 3518, 'sloooow': 3519, 'kelliec': 3520, 'michaela': 3521, 'earn': 3522, 'signature': 3523, 'couldn': 3524, 'becouse': 3525, 'trip': 3526, 'wil': 3527, 'branko': 3528, 'cant': 3529, 'certificate': 3530, 'send': 3531, \"earth's\": 3532, 'drs': 3533, 'ed': 3534, 'mathez': 3535, 'ro': 3536, 'kinzler': 3537, 'recycled': 3538, 'earth\\x80\\x99s': 3539, 'so2': 3540, 'reservoirs': 3541, 'volcanic': 3542, 'elayne': 3543, 'management': 3544, 'flexible': 3545, 'fulfill': 3546, 'mission': 3547, 'billions': 3548, 'suddenly': 3549, 'equipped': 3550, 'repost': 3551, 'toolbar': 3552, 'submission': 3553, 'typed': 3554, 'processing': 3555, 'miserable': 3556, 'unstable': 3557, 'eruption': 3558, 'magma': 3559, 'differentiate': 3560, 'orientation': 3561, 'thickness': 3562, 'uderstand': 3563, 'omim': 3564, 'onset': 3565, 'breastcancer': 3566, 'geneview': 3567, 'dbsnp': 3568, 'linke': 3569, 'located': 3570, '27': 3571, 'minor': 3572, '22': 3573, 'alpha': 3574, 'beta': 3575, 'globin': 3576, 'chains': 3577, 'listened': 3578, 'msa': 3579, 'as\\xa0clustal': 3580, 'insertion': 3581, 'evolutionarily': 3582, 'bioinformatic': 3583, 'exercises': 3584, 'encountered': 3585, '\\xa0difficulty': 3586, 'import': 3587, 'pseudo': 3588, 'replicates': 3589, 'weve': 3590, 'columns': 3591, 'guidon': 3592, 'gascuel': 3593, 'phylogenies': 3594, 'syst': 3595, 'biol': 3596, '52': 3597, '696': 3598, '704': 3599, 'trifurcation': 3600, 'ancestral': 3601, 'terminal': 3602, 'positions': 3603, 'eventhough': 3604, 'relating': 3605, 'deserves': 3606, 'exposed': 3607, 'chen': 3608, 'don\\x80\\x99t': 3609, 'reliable': 3610, 'brazilians': 3611, 'shot': 3612, 'foot': 3613, 'quots': 3614, 'lecture5': 3615, '\\x80\\x9cdarwinian\\x80\\x9d': 3616, 'beneficial': 3617, 'antibiotic': 3618, 'sweeps': 3619, 'genetic': 3620, 'increased': 3621, 'clarification': 3622, 'geneticist': 3623, 'the\\xa0': 3624, \"circle's\": 3625, 'circumference': 3626, 'diameter': 3627, \"someone's\": 3628, 'choosing': 3629, 'parameter': 3630, 'selections': 3631, 'codons': 3632, 'codon': 3633, 'weaker': 3634, 'fitness': 3635, 'synonymous\\xa0codons': 3636, 'insignificant': 3637, 'metagenomics': 3638, 'blown': 3639, 'folks': 3640, 'box1': 3641, 'lab6': 3642, 'primers': 3643, 'ligation': 3644, 'unidirectional': 3645, 'replicate': 3646, 'urlrefg': 3647, 'diagonal': 3648, 'landed': 3649, 'chromosome': 3650, '105': 3651, '133': 3652, '106': 3653, '132': 3654, 'observing': 3655, 'gist': 3656, 'inspecting': 3657, 'strain': 3658, 'conserve': 3659, 'diagonals': 3660, 'species': 3661, 'regions': 3662, 'pannel': 3663, 'comparative': 3664, 'join': 3665, 'refresh': 3666, '\\xa0does': 3667, 'megablast': 3668, 'efficiently': 3669, '\\xa0when': 3670, '\\xa0thanks': 3671, 'sessions': 3672, 'schools': 3673, 'uoft': 3674, 'meetup': 3675, 'crickets': 3676, 'substitution': 3677, 'proteins': 3678, 'searching': 3679, 'homologs': 3680, '916': 3681, '914': 3682, \"things'\": 3683, 'launch': 3684, 'firefox': 3685, 'kenneth': 3686, 'melanie': 3687, '15th': 3688, 'secure': 3689, 'stringent': 3690, 'macs': 3691, '\\xa0for': 3692, \"jnlp'\": 3693, 'for\\xa0': 3694, 'jnlp': 3695, 'pro': 3696, 'ran': 3697, 'dell': 3698, 'optiplex': 3699, '9010': 3700, 'gb': 3701, 'ram': 3702, 'nvidia': 3703, 'quadro': 3704, '600': 3705, 'distant': 3706, 'atcc': 3707, 'identifier': 3708, 'scroll': 3709, \"'892800'\": 3710, 'clicked': 3711, 'yellow': 3712, 'applets': 3713, \"person's\": 3714, 'spoke': 3715, 'advising': 3716, 'blastx': 3717, '\\xa0message': 3718, 'psi': 3719, 'beneath': 3720, 'treshold': 3721, \"'alignment'\": 3722, '160': 3723, '346': 3724, 'or\\xa0s': 3725, 'e\\xa0': 3726, 'minus': 3727, 'vale': 3728, 'screenshots': 3729, 'blastp': 3730, 'snapshots': 3731, 'reply': 3732, 'participant': 3733, 'hsp': 3734, 'colour': 3735, 'codes': 3736, 'desired': 3737, 'furthest': 3738, 'there\\x80pun': 3739, 'pun': 3740, 'sorted': 3741, 'header': 3742, 'excel': 3743, 'bars': 3744, 'rectangle': 3745, '8e': 3746, 'belong': 3747, 'muna': 3748, 'saadoon': 3749, 'entering': 3750, 'reports': 3751, 'opens': 3752, 'taxids': 3753, 'see\\xa0what': 3754, 'programs': 3755, 'frustration': 3756, 'wysiwyg': 3757, 'bioinformatics': 3758, \"''select\": 3759, \"all''\": 3760, \"''graphics''\": 3761, \"''download''\": 3762, 'edit1': 3763, 'historial': 3764, 'cookies': 3765, 'patients': 3766, 'courserian': 3767, 'partners': 3768, 'retried': 3769, 'subsets': 3770, 'guarantee': 3771, 'instructors': 3772, 'gap': 3773, 'dialign': 3774, 'clustalw': 3775, 'nucleic': 3776, 'format\\x80': 3777, \"'original'\": 3778, 'saved': 3779, 'anyplace': 3780, '\\xa0how': 3781, '\\xa0is': 3782, 'alignments': 3783, 'variety': 3784, 'formats': 3785, 'align': 3786, 'retrieve': 3787, 'editpad': 3788, '331': 3789, 'win': 3790, 'xp': 3791, 'unstuck': 3792, '\\xa0specifically': 3793, 'functional': 3794, 'paste': 3795, 'mega6': 3796, 'tips': 3797, 'txt': 3798, 'textedit': 3799, 'unclick': 3800, 'opened': 3801, 'clustaw': 3802, 'residue': 3803, 'phylogenic': 3804, '71': 3805, 'ancestor': 3806, 'ot': 3807, 'nj': 3808, 'resulting': 3809, 'bioinfomethods1': 3810, 'labs': 3811, '500': 3812, 'question3': 3813, '392': 3814, 'organism': 3815, 'larynx': 3816, 'navigator': 3817, 'edward': 3818, 'phlogeny': 3819, 'method\\x80\\x9d': 3820, 'comorbidity': 3821, 'biologically': 3822, 'fashionable': 3823, 'tobacco': 3824, \"world's\": 3825, 'ills': 3826, 'nutrition': 3827, 'baby': 3828, 'cloud': 3829, 'shifts': 3830, 'roz': 3831, 'transcript': 3832, 'theres': 3833, 'beside': 3834, 'developing': 3835, \"'reduced'\": 3836, 'sedentary': 3837, 'lifestyle': 3838, 'metabolic': 3839, 'health': 3840, 'subtitling': 3841, 'matsuda': 3842, 'all\\x80': 3843, 'realizing': 3844, 'careful': 3845, 'professionals': 3846, 'expertise': 3847, 'expanding': 3848, 'heading': 3849, 'markdown': 3850, 'caryl': 3851, 'thoughtfulness': 3852, 'tcp': 3853, 'determined': 3854, 'similarity': 3855, 'computations': 3856, 'setup': 3857, 'shouldnt': 3858, 'merged': 3859, 'ensure': 3860, 'counting': 3861, 'pagerank': 3862, 'beginner': 3863, 'discouraged': 3864, 'kindergarten': 3865, 'environment': 3866, 'adapt': 3867, 'fortunately': 3868, 'racket': 3869, 'preferred': 3870, 'groups': 3871, 'dealt': 3872, 'wrok': 3873, 'entitle': 3874, 'webpages': 3875, 'auctions': 3876, 'ads': 3877, 'cmda': 3878, 'incrementally': 3879, 'gammas': 3880, 'supporting': 3881, 'cellular': 3882, 'communications': 3883, 'apms': 3884, 'frequencies': 3885, 'senior': 3886, 'maths': 3887, 'intensive': 3888, '1150': 3889, 'sheet': 3890, 'melting': 3891, 'geologic': 3892, 'significt': 3893, 'continuing': 3894, 'canceled': 3895, 'resultant': 3896, 'misinterpreted': 3897, 'dissolved': 3898, 'buffering': 3899, 'kicks': 3900, 'determines': 3901, 'transfers': 3902, 'formation': 3903, 'hubbert': 3904, 'resemble': 3905, 'bell': 3906, 'tails': 3907, 'widely': 3908, 'bounded': 3909, 'addresses': 3910, 'arguments': 3911, 'radiative': 3912, 'forcing': 3913, 'albedo': 3914, 'feedbacks': 3915, 'stratus': 3916, 'cooling': 3917, 'humidities': 3918, 'saturated': 3919, '16x': 3920, '2x': 3921, '310': 3922, 'no2': 3923, 'accommodation': 3924, 'contributing': 3925, 'h20': 3926, 'tested': 3927, 'emission': 3928, '219': 3929, '223': 3930, 'reset': 3931, '191': 3932, 'presense': 3933, \"moist's\": 3934, 'bamboozled': 3935, 'teh': 3936, 'climatology': 3937, 'constrain': 3938, 'pollutants': 3939, 'reflectivity': 3940, 'planetary': 3941, 'comets': 3942, 'overrode': 3943, 'gong': 3944, 'steffan': 3945, 'correspond': 3946, 'panes': 3947, 'impede': 3948, 'convection': 3949, 'depressing': 3950, 'condensed': 3951, 'destroyed': 3952, 'stratospheric': 3953, 'measurements': 3954, 'budget': 3955, 'modtran': 3956, '0km': 3957, 'tropical': 3958, '348': 3959, 'm2': 3960, '400ppm': 3961, '800oppm': 3962, 'harmless': 3963, 'molecular': 3964, 'absorbing': 3965, 'emitting': 3966, 'ch4': 3967, 'hydrogen': 3968, 'oxygen': 3969, 'atom': 3970, 'molecule': 3971, 'linkage': 3972, 'tropospheric': 3973, 'deg': 3974, 'objections': 3975, 'blogsites': 3976, 'warmer': 3977, 'hilarious': 3978, 'turncoat': 3979, 'illustrate': 3980, 'wuwt': 3981, 'slaying': 3982, 'slayers': 3983, 'roy': 3984, 'spencer': 3985, 'voices': 3986, 'hmmm': 3987, 'temperatures': 3988, 'whoops': 3989, 'absorbs': 3990, 'thick': 3991, 'ar': 3992, 'nox': 3993, 'matthew': 3994, 'urlrefv': 3995, 'energybalance': 3996, 'splendid': 3997, \"francois's\": 3998, 'inspiring': 3999, 'kaltura': 4000, 'deactivated': 4001, 'infringements': 4002, 'aspect': 4003, 'nobody': 4004, 'riding': 4005, 'describing': 4006, 'rotational': 4007, 'simon': 4008, 'insures': 4009, 'valve': 4010, 'garden': 4011, 'hose': 4012, 'loosening': 4013, 'righty': 4014, 'tighty': 4015, 'lefty': 4016, 'loosey': 4017, 'tightens': 4018, 'counterclockwise': 4019, 'loosens': 4020, 'standardize': 4021, 'handed': 4022, 'bolts': 4023, 'inopportune': 4024, 'threaded': 4025, 'lid': 4026, 'pickle': 4027, 'jar': 4028, 'honored': 4029, 'seesaws': 4030, 'sky': 4031, 'perplex': 4032, 'prelim': 4033, 'stood': 4034, 'lol': 4035, 'arguing': 4036, \"skydiver's\": 4037, 'elisabed': 4038, 'rigid': 4039, 'wobbling': 4040, 'torques': 4041, 'seesaw': 4042, 'becos': 4043, 'travelling': 4044, 'sufficient': 4045, 'requiring': 4046, 'reapply': 4047, 'roll': 4048, 'ramps': 4049, 'supplying': 4050, 'hill\\xa0uses': 4051, 'pretend': 4052, 'lowering': 4053, 'transferring': 4054, \"band's\": 4055, 'hotter': 4056, 'throws': 4057, '\\xa0hope': 4058, 'stairs': 4059, 'exertion': 4060, 'skating': 4061, 'ignore': 4062, 'leaves': 4063, \"professor's\": 4064, 'undertake': 4065, 'sidewalk': 4066, 'heavy': 4067, 'muscles': 4068, 'contracting': 4069, 'resist': 4070, \"riders'\": 4071, 'wheeled': 4072, 'vehicles': 4073, 'blew': 4074, 'cycling': 4075, 'slip': 4076, 'roughness': 4077, 'slipping': 4078, 'accelerates': 4079, 'toque': 4080, 'protrusion': 4081, 'sticking': 4082, 'propelling': 4083, 'demonstrated': 4084, 'lifting': 4085, 'turning': 4086, 'forwards': 4087, 'pushing': 4088, 'pedalling': 4089, 'inercia': 4090, 'catched': 4091, 'geraldine': 4092, 'min': 4093, 'hanging': 4094, '\\xa0switch': 4095, 'gravity\\xa0': 4096, 'reacts': 4097, 'sincerely': 4098, 'vague': 4099, 'blomfield': 4100, 'disordered': 4101, 'assure': 4102, 'pan': 4103, 'boiling': 4104, 'wastes': 4105, 'freezing': 4106, 'snows': 4107, 'hi\\xa0prashanth': 4108, 'a\\xa0': 4109, 'recover': 4110, 'harness': 4111, 'chinchai': 4112, 'raw': 4113, 'calorie': 4114, 'converted': 4115, 'whichever': 4116, 'convenient': 4117, 'mounted': 4118, 'fires': 4119, \"cannon's\": 4120, 'duplicate': 4121, 'carrying': 4122, 'shoots': 4123, 'demo': 4124, 'specifying': 4125, '\\xa0episode': 4126, 'angles': 4127, 'notations': 4128, 'weighing': 4129, 'louis': 4130, 'relativity': 4131, 'weighed': 4132, 'balls': 4133, 'suffer': 4134, 'meters': 4135, 'kilogram': 4136, '10kg': 4137, 'wherever': 4138, 'eiffel': 4139, 'tower': 4140, 'caves': 4141, 'johann': 4142, 'newtons': 4143, 'aceleration': 4144, 'tricks': 4145, 'tendency': 4146, 'episode': 4147, \"'unmoving'\": 4148, 'revisiting': 4149, 'situation\\xa0': 4150, 'unmoving': 4151, 'i\\xa0': 4152, 'wagons': 4153, 'angels': 4154, 'observe': 4155, 'isolated': 4156, 'microscopic': 4157, 'transforms': 4158, 'unusable': 4159, 'directional': 4160, 'erratic': 4161, 'movements': 4162, 'appartment': 4163, 'barbra': 4164, 'strisand': 4165, 'weddings': 4166, 'funeral': 4167, 'fn': 4168, 'tt': 4169, 'proposal': 4170, '33': 4171, 'chase': 4172, 'lars': 4173, 'von': 4174, 'trier': 4175, 'anna': 4176, 'qualifies': 4177, 'i\\x80\\x99m': 4178, 'wouldn\\x80\\x99t': 4179, 'resolves': 4180, 'linklater': 4181, 'trilogy': 4182, 'jesse': 4183, 'celine': 4184, 'sunrise\\x80\\x9d': 4185, '1995': 4186, '\\x80\\x9cbofore': 4187, 'sunset\\x80\\x9d': 4188, '2004': 4189, 'reencounter': 4190, 'specially': 4191, 'focused': 4192, 'challenges': 4193, 'noel': 4194, 'coward': 4195, 'usual': 4196, 'insufferable': 4197, 'idiot': 4198, 'rationalization': 4199, 'stepping': 4200, 'develops': 4201, 'realisitic': 4202, \"coward's\": 4203, 'screenplay': 4204, 'realyse': 4205, 'popping': 4206, 'sci': 4207, 'fi': 4208, 'shares': 4209, 'aliens': 4210, 'gaspar': 4211, \"noe's\": 4212, \"'irreversible'\": 4213, 'cassell': 4214, 'monica': 4215, 'bellucci': 4216, 'smith': 4217, 'cookie': 4218, 'cutter': 4219, 'lion': 4220, \"winter'\": 4221, 'largely': 4222, 'politics': 4223, \"ii's\": 4224, '12th': 4225, 'bickering': 4226, 'turbulent': 4227, 'eleanor': 4228, 'aquitaine': 4229, 'christmas': 4230, 'traumas': 4231, 'battles': 4232, 'oddly': 4233, 'genuine': 4234, 'royal': 4235, 'resonate': 4236, 'polish': 4237, 'polanski': 4238, 'amour': 4239, 'fill': 4240, 'void': 4241, 'gotta': 4242, 'iciar': 4243, 'bolla\\xadn': 4244, 'domestic': 4245, 'psychological': 4246, 'abuse': 4247, 'brutally': 4248, 'trailer': 4249, 'mdb': 4250, 'swedish': 4251, 'scandinavian': 4252, 'korean': 4253, 'yoo': 4254, 'adultery': 4255, 'depicted': 4256, 'chasing': 4257, 'confirms': 4258, 'kabhi': 4259, 'khushi': 4260, 'kabhie': 4261, 'gham': 4262, 'doublure': 4263, 'valet': 4264, 'exacerbates': 4265, 'floor': 4266, 'expressive': 4267, 'uptight': 4268, 'neurotic': 4269, 'sassy': 4270, 'maids': 4271, \"couple's\": 4272, 'zest': 4273, 'illustrates': 4274, 'iran': 4275, 'library': 4276, 'alluded': 4277, 'tends': 4278, 'provoke': 4279, 'intending': 4280, 'struggle': 4281, 'assertion': 4282, 'tumultuous': 4283, 'presents': 4284, 'multitude': 4285, \"film's\": 4286, 'muffin': 4287, 'gripping': 4288, 'endings': 4289, 'messing': 4290, 'reminded': 4291, 'consternation': 4292, 'unresolved': 4293, 'whined': 4294, 'shocking': 4295, 'chuckled': 4296, 'hopelessly': 4297, 'johny': 4298, 'distrust': 4299, 'staged': 4300, 'gained': 4301, 'trap': 4302, 'suspence': 4303, 'masterpieces': 4304, 'relieved': 4305, 'forgives': 4306, 'discounts': 4307, 'stays': 4308, 'entertaining': 4309, 'imdb': 4310, 'trivia': 4311, 'alfred': 4312, 'guilty': 4313, 'studio': 4314, \"hitchcock's\": 4315, 'killing': 4316, 'poisoning': 4317, 'milk': 4318, 'convicting': 4319, 'mailing': 4320, 'letter': 4321, 'joan': 4322, 'fontaine': 4323, 'preview': 4324, 'refused': 4325, 'suspicious': 4326, 'opportune': 4327, 'lovable': 4328, 'scoundrel': 4329, 'monkey': 4330, 'dreaded': 4331, 'spinster': 4332, 'worse': 4333, 'maid': 4334, 'stigma': 4335, 'debonnaire': 4336, 'diabolical': 4337, 'paranoia': 4338, 'meeting': 4339, 'justified': 4340, 'relaxed': 4341, 'inspector': 4342, 'rubbernecking': 4343, 'cops': 4344, \"twiney's\": 4345, 'decor': 4346, 'photographed': 4347, 'resonated': 4348, 'persuade': 4349, 'behaviors': 4350, 'agenda': 4351, 'filmmakers': 4352, 'agnes': 4353, 'moorhead': 4354, 'unlikable': 4355, 'hoarder': 4356, 'guide': 4357, 'acceptable': 4358, 'owi': 4359, 'oversee': 4360, 'dissemination': 4361, '1940': 4362, 'stretch': 4363, 'imagination': 4364, 'celebrate': 4365, 'employed': 4366, 'device': 4367, 'tons': 4368, \"ole'\": 4369, 'drink': 4370, 'fargo': 4371, 'birdcage': 4372, 'hush': 4373, 'gal': 4374, 'friday': 4375, 'endless': 4376, 'humor': 4377, 'languages': 4378, 'satyajit': 4379, 'ray': 4380, 'pather': 4381, 'panchali': 4382, '1955': 4383, 'classic': 4384, 'depicts': 4385, 'protagonist': 4386, 'apu': 4387, 'elder': 4388, 'sister': 4389, 'durga': 4390, 'harsh': 4391, 'reinforcing': 4392, 'mahanagar': 4393, 'disconcerts': 4394, 'traditionalist': 4395, 'saleswoman': 4396, 'charulata': 4397, 'reconciliation': 4398, 'storyline': 4399, '1979': 4400, 'madison': 4401, 'county': 4402, '1999': 4403, 'springs': 4404, 'trials': 4405, 'tribulations': 4406, 'impecable': 4407, 'merryl': 4408, 'streep': 4409, 'revolutionary': 4410, '2008': 4411, 'sam': 4412, 'mendes': 4413, 'inevitable': 4414, 'zhang': 4415, 'yimou': 4416, '1994': 4417, 'manages': 4418, 'bille': 4419, 'script': 4420, 'serie': 4421, 'pond': 4422, 'relations': 4423, 'triggered': 4424, 'unhappy': 4425, 'fatal': 4426, 'disrupted': 4427, 'intense': 4428, 'affair': 4429, 'fifth': 4430, \"weren't\": 4431, 'gaslight': 4432, '1944': 4433, 'angela': 4434, 'lansbury': 4435, 'cotten': 4436, 'strictly': 4437, 'noir': 4438, 'hinged': 4439, 'exercised': 4440, 'suspenseful': 4441, \"aunt's\": 4442, 'potent': 4443, 'horrifying': 4444, 'harder': 4445, 'instigator': 4446, 'blames': 4447, 'breathes': 4448, 'mail': 4449, 'sleepless': 4450, 'seattle': 4451, 'classical': 4452, 'yesteryear': 4453, 'hepburn': 4454, 'tracy': 4455, 'rogers': 4456, 'astaire': 4457, 'errol': 4458, 'flynn': 4459, 'olivia': 4460, 'havilland': 4461, 'sweet': 4462, 'goodness': 4463, '1940s': 4464, 'handle': 4465, 'doldrums': 4466, 'cleaning': 4467, 'laura': 4468, 'petrie': 4469, 'dick': 4470, 'dyke': 4471, 'margaret': 4472, 'jim': 4473, 'anderson': 4474, 'tony': 4475, 'randolph': 4476, 'nevin': 4477, 'eddie': 4478, 'carry': 4479, 'wars': 4480, 'princess': 4481, 'leia': 4482, 'richard': 4483, 'burton': 4484, 'hudson': 4485, 'nicole': 4486, 'kidman': 4487, 'cruise': 4488, 'dianne': 4489, 'keaton': 4490, 'phylicia': 4491, 'rash\\x81d': 4492, 'kate': 4493, 'bogie': 4494, 'bicker': 4495, 'fight': 4496, 'subplot': 4497, 'romancing': 4498, 'lovely': 4499, 'jewel': 4500, 'nile': 4501, 'jes': 4502, 'trapped': 4503, 'boys': 4504, 'kid': 4505, 'sick': 4506, 'dies': 4507, 'ruth': 4508, 'gordon': 4509, 'recognized': 4510, 'clint': 4511, 'eastwood': 4512, 'cadence': 4513, 'mamet': 4514, 'quinton': 4515, 'tarantino': 4516, 'marrying': 4517, 'mille': 4518, 'photoplay': 4519, 'chapters': 4520, 'sections': 4521, 'peruse': 4522, 'ideal': 4523, 'entirety': 4524, 'jimmy': 4525, 'carole': 4526, 'lombard': 4527, 'chuckle': 4528, 'thru': 4529, 'directors': 4530, 'males': 4531, 'sil': 4532, 'portraying': 4533, 'bathrooms': 4534, 'vicariously': 4535, 'crossing': 4536, 'conventional': 4537, 'relationships': 4538, 'orchids': 4539, \"garbo's\": 4540, 'repulsion': 4541, \"prince's\": 4542, 'brute': 4543, 'servant': 4544, 'recalls': 4545, 'fantasy': 4546, 'struck': 4547, 'dialog': 4548, 'disappointment': 4549, \"husband's\": 4550, 'rejection': 4551, 'javanese': 4552, 'outfit': 4553, 'shoulders': 4554, 'sag': 4555, 'fuddy': 4556, 'duddy': 4557, 'biographical': 4558, 'qualify': 4559, \"miner's\": 4560, 'mooney': 4561, 'lee': 4562, 'jones': 4563, 'loretta': 4564, 'bio': 4565, 'carter': 4566, 'iron': 4567, 'dennis': 4568, 'thatcher': 4569, 'brazil': 4570, 'biopic': 4571, 'giant': 4572, 'lying': 4573, 'category': 4574, 'labels': 4575, 'tomato': 4576, 'silkscreened': 4577, 'photograph': 4578, 'pleased': 4579, 'wearing': 4580, 'sandwich': 4581, 'christies': 4582, \"'60's\": 4583, 'forgot': 4584, \"they've\": 4585, 'caption': 4586, 'photographs': 4587, 'newspapers': 4588, 'united': 4589, 'land': 4590, 'battlefield': 4591, 'scarred': 4592, 'rooted': 4593, 'racial': 4594, 'amid': 4595, 'headlines': 4596, 'depicting': 4597, 'civil': 4598, 'protesters': 4599, 'birmingham': 4600, 'alabama': 4601, 'fifty': 4602, 'groundbreaking': 4603, 'exemplify': 4604, 'invites': 4605, 'readers': 4606, 'blain': 4607, 'di': 4608, 'donna': 4609, 'announces': 4610, 'acquavella': 4611, 'schorr': 4612, 'underline': 4613, 'engagng': 4614, 'timely': 4615, 'broader': 4616, 'surprise': 4617, 'warholians': 4618, 'impressions': 4619, 'attend': 4620, 'signifies': 4621, 'alivness': 4622, '1970s': 4623, 'witnessed': 4624, 'flood': 4625, 'stonewall': 4626, 'disco': 4627, 'transcendental': 4628, 'meditation': 4629, \"swinger's\": 4630, 'clubs': 4631, 'attitude': 4632, 'conservative': 4633, 'assassination': 4634, 'valerie': 4635, 'solanas': 4636, 'surrounded': 4637, 'feverishly': 4638, 'walks': 4639, 'capitalize': 4640, 'allure': 4641, 'singer': 4642, 'casual': 4643, 'undid': 4644, 'belt': 4645, 'buckle': 4646, 'cotton': 4647, 'underwear': 4648, 'stamped': 4649, 'served': 4650, 'protect': 4651, 'vinyl': 4652, 'metal': 4653, 'innuendo': 4654, 'banana': 4655, 'velvet': 4656, 'flaunting': 4657, 'penis': 4658, 'combing': 4659, 'consumption': 4660, 'continuation': 4661, 'fascination': 4662, 'provoking': 4663, 'upflag': 4664, 'zippers': 4665, 'tearing': 4666, 'cellophane': 4667, 'wrappers': 4668, 'catching': 4669, 'stacks': 4670, 'conceived': 4671, 'cartons': 4672, 'forklifts': 4673, 'alice': 4674, 'flag': 4675, 'fly': 4676, 'door': 4677, 'reissues': 4678, 'undies': 4679, 'musicgraphics': 4680, 'rca': 4681, 'freelance': 4682, 'sid': 4683, 'maurer': 4684, 'biting': 4685, 'feminine': 4686, 'keith': 4687, 'skull': 4688, 'ring': 4689, 'tamer': 4690, 'risque': 4691, 'hugo': 4692, 'winterhalter': 4693, 'darryl': 4694, 'capitaliz': 4695, 'usccessful': 4696, 'gershwin': 4697, '50s': 4698, 'pressed': 4699, 'awesome': 4700, 'standards': 4701, 'bold': 4702, 'existed': 4703, 'commercially': 4704, 'stamp': 4705, 'blow': 4706, 'porn': 4707, 'studios': 4708, 'tended': 4709, 'posters': 4710, 'prominently': 4711, 'strips': 4712, 'monty': 4713, 'upside': 4714, 'censored': 4715, 'stimulate': 4716, 'thrones': 4717, 'couch': 4718, 'slippery': 4719, 'consent': 4720, 'shortage': 4721, 'plenty': 4722, 'homo': 4723, 'depictions': 4724, 'ancient': 4725, 'greek': 4726, 'roman': 4727, 'vases': 4728, 'japan': 4729, 'secret': 4730, 'rowlandson': 4731, 'aubrey': 4732, 'beardsley': 4733, 'lithograph': 4734, 'reflects': 4735, 'season': 4736, 'taboos': 4737, 'openness': 4738, 'distinct': 4739, 'viewpoint': 4740, 'inhibitions': 4741, 'removes': 4742, \"1960's\": 4743, 'refleccted': 4744, 'appearence': 4745, 'lifelong': 4746, 'follower': 4747, 'ashamed': 4748, 'failures': 4749, '1950s': 4750, 'touching': 4751, 'chilling': 4752, 'relies': 4753, 'speculation': 4754, 'subvert': 4755, 'attained': 4756, 'notoriety': 4757, 'symbolism': 4758, 'allegory': 4759, 'offended': 4760, 'asexuality': 4761, 'pose': 4762, 'keeping': 4763, \"'superstardom'\": 4764, 'scholarship': 4765, 'addressed': 4766, 'conversation': 4767, '1978': 4768, 'fs': 4769, 'loves': 4770, 'provocation': 4771, 'thats': 4772, 'admitted': 4773, 'juncture': 4774, 'cared': 4775, 'he\\x80\\x99d': 4776, '\\x80\\x9calways': 4777, 'people\\x80\\x99s': 4778, 'faces\\x80': 4779, 'intentionally': 4780, 'celibate': 4781, 'separation': 4782, 'sinless': 4783, 'sinful': 4784, 'communion': 4785, 'teachings': 4786, 'remaining': 4787, 'acceptance': 4788, 'homosexuals': 4789, 'accepted': 4790, 'lonely': 4791, 'tracks': 4792, 'arithmetic': 4793, 'meaningful': 4794, 'reader': 4795, 'attitudes': 4796, 'warholian': 4797, 'contradictory': 4798, 'illogical': 4799, 'premises': 4800, 'nik': 4801, 'cohn': 4802, 'march': 4803, 'contracts': 4804, 'harcourt': 4805, 'brace': 4806, 'jovanovich': 4807, 'contract': 4808, 'anecdotes': 4809, 'stoned': 4810, 'channel': 4811, 'voice': 4812, 'dictation': 4813, 'collaborator': 4814, 'companion': 4815, 'twelve': 4816, '1970': 4817, '1982': 4818, 'numerous': 4819, 'chelsea': 4820, 'girls': 4821, '1966': 4822, 'ciao': 4823, '1972': 4824, 'transcriptionist': 4825, '1975': 4826, '1987': 4827, 'contributor': 4828, 'serving': 4829, 'president': 4830, 'enterprises': 4831, 'named': 4832, 'founding': 4833, 'members': 4834, 'testament': 4835, 'dissolution': 4836, 'october': 4837, '2011': 4838, 'authentication': 4839, 'consulted': 4840, 'held': 4841, 'agent': 4842, 'i17g3wpdfa4': 4843, 'denis': 4844, 'contributions': 4845, 'wealth': 4846, 'springboard': 4847, 'perusing': 4848, 'generous': 4849, \"jay's\": 4850, 'twin': 4851, 'twa': 4852, \"800's\": 4853, 'july': 4854, '1996': 4855, 'nyc': 4856, 'crashed': 4857, 'island': 4858, 'detective': 4859, 'portland': 4860, 'oregon': 4861, 'police': 4862, 'department': 4863, 'idealism': 4864, 'summer': 4865, '1967': 4866, 'culmination': 4867, 'woodstock': 4868, 'altamont': 4869, 'december': 4870, 'utopia': 4871, 'altered': 4872, 'naivete': 4873, 'cooperation': 4874, 'unwelcome': 4875, 'nearly': 4876, 'victims': 4877, 'silkscreen': 4878, 'startling': 4879, 'glaringly': 4880, 'bills': 4881, 'literally': 4882, 'mimicking': 4883, 'commodification': 4884, 'highs': 4885, 'afford': 4886, 'jackson': 4887, 'dying': 4888, 'proto': 4889, 'teenager': 4890, 'worshiping': 4891, 'kinds': 4892, 'obscene': 4893, 'attributable': 4894, 'imagines': 4895, '99': 4896, 'unemployed': 4897, 'scraping': 4898, \"sotheby's\": 4899, 'cynical': 4900, 'temporary': 4901, 'touring': 4902, 'walls': 4903, 'commission': 4904, 'bag': 4905, 'networking': 4906, 'advent': 4907, \"'touched\": 4908, \"fame'\": 4909, 'urge': 4910, 'succeed': 4911, 'perfection': 4912, 'gold': 4913, 'buyer': 4914, 'monetary': 4915, 'iikka': 4916, 'portfolio': 4917, 'tie': 4918, 'sharp': 4919, 'soft': 4920, 'industry': 4921, 'incidentally': 4922, \"who've\": 4923, 'scarcity': 4924, 'residual': 4925, 'anxiety': 4926, 'manifest': 4927, 'imagined': 4928, 'milliion': 4929, 'heaven': 4930, 'drawbacks': 4931, 'petrified': 4932, 'apologize': 4933, 'inappropriately': 4934, 'investing': 4935, 'graduating': 4936, \"family's\": 4937, 'lover': 4938, 'primarily': 4939, 'ny': 4940, 'bulk': 4941, 'befriended': 4942, 'hung': 4943, 'sixth': 4944, \"guggenheim's\": 4945, 'benefits': 4946, 'grandchildren': 4947, 'kent': 4948, 'complying': 4949, 'wishes': 4950, 'collects': 4951, 'herb': 4952, 'dorothy': 4953, 'vogel': 4954, 'amass': 4955, 'paul': 4956, 'suing': 4957, 'heiress': 4958, 'herself': 4959, 'eighties': 4960, 'strategic': 4961, 'planning': 4962, 'passenger': 4963, 'jet': 4964, 'dozen': 4965, 'piloted': 4966, 'endowment': 4967, 'plaintiffs': 4968, 'businessman': 4969, 'scraped': 4970, 'unlikely': 4971, 'staggeringly': 4972, 'amounts': 4973, 'motivated': 4974, 'investments': 4975, 'undoubtedly': 4976, 'desiree': 4977, 'stole': 4978, 'stranger': 4979, 'fallen': 4980, 'favor': 4981, 'rebirth': 4982, 'astounding': 4983, 'arena': 4984, 'genii': 4985, 'ignored': 4986, 'genius': 4987, 'prophetically': 4988, 'norman': 4989, 'captured': 4990, 'hearts': 4991, 'evoke': 4992, 'ties': 4993, 'uncanny': 4994, \"artist's\": 4995, 'investors': 4996, 'loosing': 4997, 'grown': 4998, 'michelangelo': 4999, 'caravaggio': 5000, 'matisse': 5001, 'rembrandy': 5002, 'vermeer': 5003, 'rising': 5004, 'painters': 5005, 'plying': 5006, 'goods': 5007, '1800s': 5008, 'craftsmen': 5009, 'ghiberti': 5010, 'micehlangelo': 5011, 'da': 5012, 'vinci': 5013, 'service': 5014, 'supply': 5015, 'estate': 5016, 'yup': 5017, 'giovanni': 5018, 'bernini': 5019, '17th': 5020, 'sculptor': 5021, 'architect': 5022, 'fortune': 5023, 'pope': 5024, 'aristocrats': 5025, 'tears': 5026, 'tintillate': 5027, 'spirituality': 5028, 'marble': 5029, 'drape': 5030, 'ecstacy': 5031, 'breathtaking': 5032, 'websites': 5033, 'devoted': 5034, 'devoutly': 5035, 'bernini\\x80\\x99s': 5036, 'portrayal': 5037, 'ecstasy': 5038, 'tailors': 5039, 'shoemakers': 5040, 'craft': 5041, \"scultptures'\": 5042, \"paintings'\": 5043, 'agreed': 5044, '19th': 5045, 'beholder': 5046, 'subjective': 5047, 'adore': 5048, 'brag': 5049, 'owning': 5050, 'deems': 5051, 'equalizer': 5052, 'nail': 5053, 'furniture': 5054, 'survive': 5055, 'madelyn': 5056, 'ness': 5057, 'marking': 5058, 'selves': 5059, 'beethoven': 5060, 'shakespeare': 5061, 'pavlova': 5062, 'humanity': 5063, 'overdemand': 5064, 'published': 5065, 'et': 5066, '20140514': 5067, 'haves': 5068, 'nots': 5069, 'contrast': 5070, 'attracts': 5071, 'sensitive': 5072, 'recall': 5073, 'desperately': 5074, 'truman': 5075, 'capote': 5076, 'contempory': 5077, 'older': 5078, 'famiies': 5079, 'acclaim': 5080, 'expense': 5081, 'lifetimes': 5082, 'huddled': 5083, 'pint': 5084, 'hoxton': 5085, \"'unknowns'\": 5086, 'incrdible': 5087, 'spirit': 5088, \"'great\": 5089, \"artworks'\": 5090, 'nowadays': 5091, 'restitution': 5092, 'robbed': 5093, 'nazis': 5094, 'fuss': 5095, 'shiver': 5096, 'exhibited': 5097, 'illegally': 5098, 'justice': 5099, 'grip': 5100, 'oftentimes': 5101, 'exhibits': 5102, 'coffers': 5103, 'minededness': 5104, 'motivations': 5105, 'purchasing': 5106, 'originals': 5107, 'reproductions': 5108, 'surges': 5109, 'oppressive': 5110, 'bordeaux': 5111, 'wine': 5112, 'documentary': 5113, 'meagan': 5114, 'hype': 5115, 'bandwagon': 5116, 'travels': 5117, 'pot': 5118, 'hot': 5119, 'hotel': 5120, 'lowered': 5121, 'tray': 5122, '5000': 5123, 'legacy': 5124, 'phenomenal': 5125, \"jeff's\": 5126, 'balloon': 5127, 'sculptures': 5128, 'invigorating': 5129, 'marks': 5130, 'convey': 5131, 'tackles': 5132, 'mortality': 5133, 'butterflies': 5134, \"koons'\": 5135, 'crass': 5136, 'garish': 5137, 'redeemable': 5138, 'qualities': 5139, 'changer': 5140, 'exhaustion': 5141, 'stopped': 5142, 'modernists': 5143, 'signify': 5144, 'judgment': 5145, 'piety': 5146, 'emancipation': 5147, 'perceives': 5148, 'ignores': 5149, 'recognizes': 5150, 'instantiates': 5151, 'peculiar': 5152, 'passage': 5153, 'thierry': 5154, 'duve': 5155, 'matt': 5156, 'chief': 5157, 'archivist': 5158, 'mins': 5159, '29': 5160, 'muses': 5161, 'styles': 5162, 'employ': 5163, 'considerable': 5164, 'theirs': 5165, \"'factory'\": 5166, 'workers': 5167, 'customer': 5168, 'originated': 5169, 'patronage': 5170, 'dependence': 5171, '\\x80\\x8b\\x80\\x8bhim': 5172, 'ambitions': 5173, 'displaying': 5174, 'worldwide': 5175, \"'time'\": 5176, \"people's\": 5177, 'hyperrealism': 5178, 'deliberately': 5179, 'disengaged': 5180, 'disaster': 5181, 'devoid': 5182, 'abernethy': 5183, 'warhol\\x80\\x99s': 5184, 'we\\x80\\x99re': 5185, 'immaculate': 5186, 'topography': 5187, 'remediated': 5188, 'silence': 5189, 'expressionism': 5190, 'flat': 5191, 'echoes': 5192, 'cinematic': 5193, 'passivity': 5194, 'indifference': 5195, 'empowers': 5196, 'primary': 5197, '490': 5198, 'feeling': 5199, 'imparting': 5200, 'posited': 5201, 'kinkade': 5202, 'divorced': 5203, 'screenprinting': 5204, 'prize': 5205, 'frame': 5206, 'obhnijaovow': 5207, 'distorted': 5208, 'critics': 5209, 'profit': 5210, 'evalution': 5211, 'consequent': 5212, 'captures': 5213, 'todayspapersting': 5214, 'vindication': 5215, 'vividly': 5216, 'saturday': 5217, 'evening': 5218, 'lttle': 5219, 'disappointed': 5220, 'abilities': 5221, 'loses': 5222, 'lets': 5223, 'crossed': 5224, 'writers': 5225, 'connect': 5226, 'deepest': 5227, 'unconscious': 5228, 'freud': 5229, 'describes': 5230, 'uncoordinated': 5231, 'instinctual': 5232, 'trends': 5233, 'disengages': 5234, 'ther': 5235, 'participation': 5236, 'symbolise': 5237, 'stripping': 5238, 'colored': 5239, 'repetitions': 5240, 'forced': 5241, 'webcams': 5242, 'earthcam': 5243, 'chrysostom': 5244, 'byzantine': 5245, 'speechless': 5246, 'siem': 5247, 'reap': 5248, 'cambodia': 5249, 'decade': 5250, 'birds': 5251, 'chirp': 5252, 'atop': 5253, 'flags': 5254, 'wave': 5255, 'grave': 5256, 'timerefam': 5257, 'monday': 5258, 'pennsylvania': 5259, 'iconostasis': 5260, 'stare': 5261, 'roots': 5262, 'repetitive': 5263, 'rituals': 5264, 'peaceful': 5265, 'eeery': 5266, 'prepared': 5267, 'subtlety': 5268, 'contemplation': 5269, 'tomorrow': 5270, 'lunch': 5271, 'supper': 5272, 'dove': 5273, 'delightful': 5274, 'im': 5275, 'cocktail': 5276, 'backdrop': 5277, 'desert': 5278, 'rural': 5279, 'remote': 5280, 'approve': 5281, 'pleasure': 5282, 'painful': 5283, 'generates': 5284, 'expanded': 5285, 'temporality': 5286, 'stress': 5287, 'quo': 5288, 'approached': 5289, 'huh': 5290, 'footage': 5291, 'hair': 5292, 'picks': 5293, 'telescope': 5294, 'smiles': 5295, 'gesture': 5296, 'laugh': 5297, 'quisitive': 5298, 'scrutinizing': 5299, 'curiously': 5300, 'wanting': 5301, 'anticipating': 5302, 'screening': 5303, 'houston': 5304, 'proud': 5305, 'nodded': 5306, 'actively': 5307, 'judge': 5308, 'actresses': 5309, 'portray': 5310, 'engage': 5311, 'commentary': 5312, 'warhols': 5313, 'ronald': 5314, 'fortuna': 5315, 'honesty': 5316, 'mesmerizing': 5317, 'horror': 5318, 'uncomfortable': 5319, 'voyeurism': 5320, 'slowed': 5321, 'musicians': 5322, 'britta': 5323, 'soundtrack': 5324, 'ten': 5325, 'dvd': 5326, 'hypnotic': 5327, 'mpire': 5328, 'surprises': 5329, 'willingness': 5330, 'mutual': 5331, 'admiration': 5332, 'fractionally': 5333, 'kristy': 5334, 'viola': 5335, 'cinema': 5336, 'freedom': 5337, \"media's\": 5338, 'recolonized': 5339, 'dominant': 5340, 'contentious': 5341, 'las': 5342, 'vegas': 5343, 'ritual': 5344, 'personalities': 5345, \"'screen\": 5346, \"test'\": 5347, 'actor': 5348, 'lighting': 5349, 'scrutiny': 5350, 'filming': 5351, 'extending': 5352, 'comfort': 5353, 'zone': 5354, 'faces': 5355, \"'human'\": 5356, \"'icons'\": 5357, 'creates': 5358, 'aura': 5359, 'nico': 5360, 'shes': 5361, 'gaze': 5362, 'masks': 5363, 'wear': 5364, 'wore': 5365, 'suit': 5366, 'facade': 5367, 'react': 5368, 'peeping': 5369, 'comparisons': 5370, 'sitters': 5371, 'strenuous': 5372, 'stressful': 5373, 'dead': 5374, 'dylan': 5375, 'fleeting': 5376, 'poignant': 5377, 'diversity': 5378, 'surprisingly': 5379, 'improvisation': 5380, 'caught': 5381, 'interrogated': 5382, 'dealers': 5383, 'gallerists': 5384, 'subverted': 5385, 'ultimately': 5386, 'utopian': 5387, 'dreaming': 5388, 'innovation': 5389, 'banal': 5390, 'celebrated': 5391, 'pursuit': 5392, 'immortalized': 5393, 'cola': 5394, 'enslaved': 5395, 'lash': 5396, 'battle': 5397, 'neutrality': 5398, 'idolized': 5399, 'prefiguring': 5400, 'pursuits': 5401, 'ranging': 5402, 'oeuvre': 5403, 'marina': 5404, \"abramovic's\": 5405, 'superficiality': 5406, 'intensity': 5407, 'presence': 5408, 'seminal': 5409, 'dependent': 5410, 'ineffable': 5411, 'unreproducible': 5412, 'uniqueness': 5413, 'repeatable': 5414, 'lacking': 5415, 'materiality': 5416, 'imo': 5417, 'nineteen': 5418, 'months': 5419, 'begged': 5420, 'xphhidldike': 5421, 'tyr9plwjy2i': 5422, 'aaaaaaaabjq': 5423, 'elcsuntlcww': 5424, 's1600': 5425, '252cwarhol': 5426, 'tweak': 5427, 'manipulating': 5428, 'compensate': 5429, 'directing': 5430, 'nervous': 5431, 'comics': 5432, 'newpapers': 5433, 'coincidently': 5434, 'antiques': 5435, 'twice': 5436, 'campbell': 5437, 'tens': 5438, 'mom': 5439, 'disconnected': 5440, 'godfather': 5441, 'uploads': 5442, \"mother's\": 5443, 'lettered': 5444, 'efforts': 5445, 'pamphlets': 5446, 'editors': 5447, 'friends': 5448, 'signing': 5449, 'smothering': 5450, \"'sleep'\": 5451, 'relatively': 5452, 'widespread': 5453, 'informations': 5454, 'internationally': 5455, 'representing': 5456, 'protected': 5457, '3d': 5458, \"image's\": 5459, 'portion': 5460, 'identify': 5461, 'restriction': 5462, 'blogs': 5463, 'excludes': 5464, 'educational': 5465, 'guidelines': 5466, 'argentina': 5467, 'legislation': 5468, 'stipulates': 5469, 'collages': 5470, 'copyrighted': 5471, 'fund': 5472, 'scholarships': 5473, 'ill': 5474, 'karen': 5475, 'borrowed': 5476, 'gaga': 5477, 'lana': 5478, 'del': 5479, 'rey': 5480, 'lawyers': 5481, 'flattered': 5482, '50th': 5483, 'momento': 5484, \"how's\": 5485, 'weirdness': 5486, 'acclaimed': 5487, 'draftsman': 5488, 'precious': 5489, 'earliest': 5490, 'explorations': 5491, 'contributed': 5492, 'dialogue': 5493, 'chinese': 5494, 'yue': 5495, 'minjun': 5496, 'wang': 5497, 'guangyi': 5498, 'emphasis': 5499, 'consumerist': 5500, 'broad': 5501, 'takashi': 5502, 'murakami': 5503, \"murakami's\": 5504, 'animated': 5505, 'kenya': 5506, \"west's\": 5507, '6chs4x2uqcq': 5508, 'collaboratin': 5509, 'vein': 5510, 'wigs': 5511, 'recognise': 5512, 'met': 5513, 'wig': 5514, 'transform': 5515, 'obamam': 5516, 'obama': 5517, 'infringement': 5518, 'george': 5519, \"bush's\": 5520, 'micheel': 5521, 'collaborated': 5522, 'conquer': 5523, 'fav': 5524, 'gswzyvtx5tu': 5525, 'reexamine': 5526, 'cult': 5527, 'strategies': 5528, 'collaging': 5529, 'examine': 5530, \"culture's\": 5531, 'ethical': 5532, 'vintage': 5533, 'hockney': 5534, 'tangent': 5535, 'searched': 5536, 'articles': 5537, 'unexpected': 5538, 'chuck': 5539, 'acquaintance': 5540, 'san': 5541, 'greenwich': 5542, 'shop': 5543, 'street': 5544, 'mister': 5545, 'brainwash': 5546, 'nv': 5547, 'sr': 5548, 'screened': 5549, 'c4': 5550, 'par': 5551, 'legend': 5552, 'celeb': 5553, 'wtf': 5554, 'metropolitan': 5555, 'conducted': 5556, 'sixty': 5557, 'creators': 5558, 'elizabeth': 5559, 'peyton': 5560, 'alex': 5561, 'katz': 5562, 'ai': 5563, 'weiwei': 5564, 'mapplethorpe': 5565, 'chapelle': 5566, 'amanda': 5567, 'lepore': 5568, \"'s\": 5569, 'boils': 5570, 'captivated': 5571, 'fueling': 5572, 'lenses': 5573, 'freudian': 5574, 'anthropological': 5575, 'ambiguous': 5576, 'taste': 5577, 'embody': 5578, 'sake': 5579, 'definately': 5580, 'comprehend': 5581, 'dynamically': 5582, 'ww': 5583, 'countries': 5584, 'suffered': 5585, 'industrialization': 5586, 'flowing': 5587, 'infatuated': 5588, 'illusion': 5589, 'fulfilment': 5590, 'critisize': 5591, 'emancipate': 5592, 'multiplying': 5593, 'emptiness': 5594, 'comfortably': 5595, 'shy': 5596, 'screenprint': 5597, 'manifactured': 5598, 'philosophical': 5599, 'backgrounds': 5600, 'ect': 5601, 'theories': 5602, 'histories': 5603, 'aesthetically': 5604, 'pleasing': 5605, 'diminishes': 5606, 'encourrage': 5607, 'hole': 5608, 'projection': 5609, 'appreciation': 5610, 'consume': 5611, 'boxes': 5612, 'supermarket': 5613, 'collector': 5614, 'acreator': 5615, 'twentieth': 5616, 'paradise': 5617, 'murders': 5618, 'chairs': 5619, 'insightful': 5620, 'confounding': 5621, 'judging': 5622, 'ben': 5623, 'jonson': 5624, 'folio': 5625, 'durability': 5626, 'criteria': 5627, 'informs': 5628, 'pov': 5629, 'deficit': 5630, 'disorder': 5631, 'understandably': 5632, 'authorization': 5633, 'gorgeous': 5634, 'teachers': 5635, 'dan': 5636, \"archaeology's\": 5637, 'secrets': 5638, 'alcock': 5639, 'exceptional': 5640, 'favourite': 5641, 'chose': 5642, 'rubs': 5643, 'imply': 5644, 'amused': 5645, 'capable': 5646, 'barely': 5647, 'lenght': 5648, 'supposedly': 5649, 'voluntarily': 5650, \"sue's\": 5651, 'jotted': 5652, 'complain': 5653, 'enroll': 5654, 'associates': 5655, 'spelling': 5656, 'edie': 5657, 'examined': 5658, \"video's\": 5659, 'beatles': 5660, 'monotonous': 5661, 'fabulous': 5662, 'flamboyant': 5663, 'rude': 5664, 'received': 5665, 'vying': 5666, 'implying': 5667, 'proverbial': 5668, 'protest': 5669, 'reserve': 5670, 'judgments': 5671, 'critiques': 5672, 'surveys': 5673, \"'suggestions'\": 5674, 'rehearsed': 5675, 'engaged': 5676, 'broadcast': 5677, 'achieved': 5678, 'moocs': 5679, 'taught': 5680, 'plan': 5681, 'diptych': 5682, 'ticked': 5683, 'apology': 5684, 'passes': 5685, 'biography': 5686, 'profession': 5687, 'ourselves': 5688, 'south': 5689, 'africa': 5690, \"'top'\": 5691, 'priveledged': 5692, \"'free'\": 5693, 'individuals': 5694, 'fell': 5695, 'progresses': 5696, 'scottish': 5697, 'accent': 5698, 'pronounced': 5699, 'fiontan': 5700, 'speaks': 5701, 'elgin': 5702, 'marbles': 5703, 'prominent': 5704, 'curiosity': 5705, 'interestingly': 5706, 'discussions': 5707, 'debates': 5708, 'conformist': 5709, 'unusual': 5710, 'cave': 5711, 'scratchings': 5712, 'icons': 5713, 'landscapes': 5714, \"'painted'\": 5715, \"'staying'\": 5716, 'concerned': 5717, 'scotland': 5718, 'personna': 5719, 'bizarre': 5720, 'personality': 5721, 'tool': 5722, 'genuinely': 5723, 'warohl': 5724, 'wikipedia': 5725, 'font': 5726, 'cough': 5727, 'precedence': 5728, 'conartwhait': 5729, 'paramount': 5730, 'vital': 5731, 'considerd': 5732, 'contriving': 5733, 'borrows': 5734, 'mades': 5735, 'readily': 5736, 'seized': 5737, 'nah': 5738, 'purist': 5739, 'heavily': 5740, 'multiples': 5741, 'invariably': 5742, 'overlooked': 5743, 'celebs': 5744, 'kirsty': 5745, 'baring': 5746, \"'no\": 5747, \"'anti\": 5748, 'rawness': 5749, \"duchamp's\": 5750, 'fountain': 5751, 'punches': 5752, 'clichd': 5753, 'vase': 5754, 'punk': 5755, 'excuse': 5756, 'honestly': 5757, \"'poor\": 5758, 'admirable': 5759, 'nuanced': 5760, 'fullest': 5761, 'polemical': 5762, 'isnt': 5763, \"'it\": 5764, 'views': 5765, 'jaw': 5766, 'exploration': 5767, 'trash': 5768, 'tamara': 5769, 'gettint': 5770, \"'ready\": 5771, \"made'\": 5772, 'prioritisation': 5773, 'anti': 5774, \"'meaning'\": 5775, 'coy': 5776, \"'intention'\": 5777, 'irony': 5778, 'spectacle': 5779, 'directs': 5780, 'fickle': 5781, 'greatboon': 5782, 'baffled': 5783, 'presley': 5784, 'someway': 5785, 'pam': 5786, 'lapped': 5787, 'polaroids': 5788, 'framing': 5789, 'parcel': 5790, 'catherine': 5791, 'prioritises': 5792, 'surrealist': 5793, 'brain': 5794, 'conception': 5795, 'phrase': 5796, 'idealization': 5797, \"marilyn's\": 5798, 'andrea': 5799, 'disintegration': 5800, 'corrupts': 5801, 'deterioration': 5802, 'heralds': 5803, 'celebrates': 5804, 'elevates': 5805, 'treats': 5806, 'letting': 5807, 'peoples': 5808, 'contrived': 5809, 'hello': 5810, 'confess': 5811, 'celia': 5812, 'cruz': 5813, 'cuban': 5814, 'santo': 5815, 'domingo': 5816, 'prevails': 5817, '\\x80\\x8b\\x80\\x8bartistic': 5818, 'achievement': 5819, '1917': 5820, 'marcel': 5821, 'categorical': 5822, 'urinary': 5823, 'questioning': 5824, 'undermining': 5825, 'secular': 5826, '\\x80\\x8b\\x80\\x8bso': 5827, 'academy': 5828, 'ceases': 5829, 'pure': 5830, 'manifestations': 5831, 'arte': 5832, 'povera': 5833, 'happenings': 5834, 'precepts': 5835, 'kosuth': 5836, 'rauschenberg': 5837, 'abramovic': 5838, 'klein': 5839, 'predominant': 5840, 'precursor': 5841, 'consecration': 5842, 'avid': 5843, 'upper': 5844, 'eager': 5845, 'elite': 5846, 'goyesco': 5847, 'dreams': 5848, 'prodigal': 5849, 'graffiti': 5850, 'streets': 5851, 'unprecedented': 5852, 'characteristics': 5853, 'borders': 5854, 'dadaism': 5855, 'dada': 5856, 'gretel': 5857, 'gently': 5858, 'perceive': 5859, 'schema': 5860, 'dimentional': 5861, 'bare': 5862, 'dynamics': 5863, 'driven': 5864, 'noted': 5865, 'observer': 5866, 'facilitated': 5867, \"marc's\": 5868, 'showcases': 5869, 'involving': 5870, 'master': 5871, 'creatives': 5872, 'responsive': 5873, 'maintained': 5874, 'neutral': 5875, 'analyze': 5876, 'historian': 5877, 'mentors': 5878, 'tough': 5879, 'objectivity': 5880, 'extravagant': 5881, 'exotic': 5882, 'shade': 5883, 'london': 5884, 'enticing': 5885, 'germaine': 5886, 'greer': 5887, 'paula': 5888, 'rego': 5889, 'detached': 5890, 'hood': 5891, 'referential': 5892, 'loop': 5893, \"does't\": 5894, 'invite': 5895, 'gazing': 5896, 'hemingway': 5897, 'postings': 5898, 'yong': 5899, 'hau': 5900, 'initiated': 5901, 'picked': 5902, 'distilling': 5903, 'endeavour': 5904, 'resolved': 5905, '4x4': 5906, '2x2': 5907, 'patches': 5908, 'patch': 5909, 'magically': 5910, \"'y'\": 5911, 'adjust': 5912, 'pleash': 5913, 'messed': 5914, 'planes': 5915, 'containing': 5916, 'sought': 5917, 'pyramid': 5918, 'apex': 5919, 'polygon': 5920, 'circle': 5921, 'misclassified': 5922, 'principle': 5923, 'classifiable': 5924, 'boundary': 5925, 'constraining': 5926, 'intersects': 5927, 'intersect': 5928, 'magnitude': 5929, 'aforementioned': 5930, 'arbitrarily': 5931, 'daft': 5932, 'badly': 5933, 'typos': 5934, 'pretraining': 5935, 'labelled': 5936, 'sensibly': 5937, '11b': 5938, 'distinguish': 5939, 'confuses': 5940, 'ipad': 5941, 'accidentally': 5942, 'downvote': 5943, 'empirical': 5944, 'rectified': 5945, 'datas': 5946, 'overfitting': 5947, 'assistance': 5948, '11e': 5949, 'particle': 5950, 'particles': 5951, 'bath': 5952, 'proba': 5953, 'bility': 5954, 'obey': 5955, '\\x80\\x9cthermal': 5956, 'equilibrium\\x80\\x9d': 5957, 'maxwell': 5958, 'perron': 5959, 'frobenius': 5960, 'periodic': 5961, 'preserves': 5962, 'elsewhere': 5963, 'amd': 5964, 'sa': 5965, 'rct': 5966, 'ved': 5967, '0ckebebywew': 5968, 'ei': 5969, 'dsytumnuaphwsgbs84gwaw': 5970, 'usg': 5971, 'afqjcnhqdeycjsr9fzphpwlvkfbxgpl7ya': 5972, 'crank': 5973, 'convince': 5974, 'simulations': 5975, 'googling': 5976, 'concludes': 5977, 'multilying': 5978, 'apart': 5979, 'sneaks': 5980, 'metropolis': 5981, 'hastings': 5982, 'mcmc': 5983, 'gibbs': 5984, 'induced': 5985, 'stab': 5986, 'specified': 5987, 'exponentials': 5988, 'picking': 5989, 'proving': 5990, 'joining': 5991, 'ideally': 5992, 'inevitably': 5993, 'arrive': 5994, 'sloppy': 5995, 'outlined': 5996, 'thermodynamic': 5997, 'mild': 5998, \"reif's\": 5999, 'restricted': 6000, 'unnormalized': 6001, 'proportional': 6002, 'exp': 6003, 'systematically': 6004, 'ising': 6005, 'preferably': 6006, 'batch': 6007, \"answer's\": 6008, 'sine': 6009, '\\x88\\x9e': 6010, 'sin': 6011, 'clumped': 6012, 'settles': 6013, 'kn': 6014, 'sejnowski': 6015, 'estimator': 6016, 'notation': 6017, 'likelyhood': 6018, 'datacase': 6019, 'iterations': 6020, 'summing': 6021, 'dividing': 6022, 'miguel': 6023, 'precisely': 6024, 'worthwhile': 6025, 'restart': 6026, 'avoiding': 6027, 'afterwards': 6028, 'aslo': 6029, 'minimas': 6030, '14a': 6031, 'elaborate': 6032, 'aggregated': 6033, 'factorial': 6034, '0625': 6035, 'auto': 6036, 'autoencoder': 6037, 'papers': 6038, 'resources': 6039, 'hinted': 6040, 'nuclear': 6041, 'station': 6042, 'theoretically': 6043, 'vladimir': 6044, 'homogeneous': 6045, 'layers': 6046, 'theoretical': 6047, '16a': 6048, 'demonstration': 6049, 'dbm': 6050, '7m40s': 6051, 'yep': 6052, 'headphones': 6053, 'explanatory': 6054, 'contractive': 6055, 'behave': 6056, 'sparse': 6057, 'orphan': 6058, 'hyperparameters': 6059, 'scratch': 6060, 'server': 6061, 'qualification': 6062, 'manager': 6063, '10b': 6064, 'summation': 6065, 'differentiating': 6066, 'dmitri': 6067, 'representations': 6068, 'tuned': 6069, 'couplings': 6070, 'cdot': 6071, 'consistency': 6072, 'chat': 6073, 'activating': 6074, 'intricate': 6075, 'disrupt': 6076, 'implicit': 6077, 'unbiased': 6078, 'impossible': 6079, \"we'd\": 6080, 'bouncing': 6081, 'simulate': 6082, 'reached': 6083, 'mixing': 6084, 'guesses': 6085, 'projections': 6086, 'chi': 6087, 'squared': 6088, 'procedures': 6089, 'survey': 6090, 'randomness': 6091, 'unfair': 6092, 'unknown': 6093, 'bernoulli': 6094, 'drops': 6095, 'exponentially': 6096, 'ups': 6097, 'coupling': 6098, 'thesis': 6099, 'dbwilson': 6100, 'wildly': 6101, 'dissimilar': 6102, 'haunted': 6103, 'wander': 6104, 'doors': 6105, 'bloody': 6106, 'tiles': 6107, 'cobwebby': 6108, 'sinister': 6109, 'bedroom': 6110, 'eerie': 6111, 'forth': 6112, 'wanders': 6113, 'finds': 6114, 'rooms': 6115, 'conclude': 6116, 'trapdoor': 6117, 'dungeon': 6118, 'mapping': 6119, 'equivalence': 6120, 'clearer': 6121, 'mrf': 6122, 'rnns': 6123, 'steered': 6124, 'framework': 6125, 'contraints': 6126, 'routine': 6127, 'automatically': 6128, 'normalized': 6129, 'parametrises': 6130, 'minimise': 6131, 'lagrangian': 6132, 'equality': 6133, 'leq': 6134, 'contraint': 6135, 'implied': 6136, 'ahh': 6137, 'orthogonal': 6138, 'overshoot': 6139, 'optimizer': 6140, 'gd': 6141, '2': 6142, 'vanishing': 6143, 'disadvantages': 6144, 'conjugate': 6145, 'fewer': 6146, 'calculating': 6147, 'hessian': 6148, 'surfaces': 6149, 'unfold': 6150, 'http': 6151, 'spark': 6152, 'rigorous': 6153, 'arrow': 6154, 'denotes': 6155, 'logit': 6156, 'deduce': 6157, 'defies': 6158, 'trivial': 6159, 'construed': 6160, 'recurrence': 6161, 'lightly': 6162, 'q6': 6163, \"question's\": 6164, '234': 6165, 'pity': 6166, 'nlp': 6167, \"regular'\": 6168, 'functionality': 6169, 'retain': 6170, 'dictates': 6171, 'timeline': 6172, 'suitable': 6173, 'backed': 6174, 'postulating': 6175, 'viewpoints': 6176, 'unexplained': 6177, 'incredibly': 6178, 'tense': 6179, 'plural': 6180, 'previously': 6181, 'jargon': 6182, 'overcomes': 6183, 'rendered': 6184, 'omit': 6185, 'appropriately': 6186, 'omitted': 6187, 'outgoing': 6188, 'activations': 6189, 'assign': 6190, 'sequentially': 6191, 'prefers': 6192, \"'1'\": 6193, 'jw': 6194, \"'start\": 6195, \"state'\": 6196, 'infers': 6197, 'proceed': 6198, 'absence': 6199, 'intuition': 6200, 'escape': 6201, 'competition': 6202, 'collaborative': 6203, 'filtering': 6204, 'dropping': 6205, 'included': 6206, 'basis': 6207, 'deliver': 6208, \"u'\": 6209, \"doen't\": 6210, 'dissapeared': 6211, 'outer': 6212, 'cedomir': 6213, \"igaly's\": 6214, 'fu': 6215, 'enspace': 6216, 'transpose': 6217, 'agreement': 6218, 'rafael': 6219, 'commutative': 6220, 'vu': 6221, 'iu': 6222, 'ju': 6223, 'misunderstood': 6224, 'generality': 6225, '21': 6226, '55': 6227, '77': 6228, 'kids': 6229, \"douglas's\": 6230, \"math'\": 6231, \"wolfgang's\": 6232, 'inbox': 6233, 'compelling': 6234, 'trusts': 6235, 'dig': 6236, 'tensors': 6237, 'league': 6238, 'moderators': 6239, 'incorporateing': 6240, 'formulae': 6241, 'graphs': 6242, 'counterparts': 6243, 'sentense': 6244, 'nns': 6245, 'elm': 6246, 'lerning': 6247, 'unconvenient': 6248, 'elms': 6249, 'promising': 6250, \"barron's\": 6251, 'bounds': 6252, 'superpositions': 6253, 'sigmoidal': 6254, '1993': 6255, 'useless': 6256, 'dimensional': 6257, 'initialization': 6258, 'mlp': 6259, 'arises': 6260, 'tas': 6261, 'dense': 6262, 'responces': 6263, 'dence': 6264, 'density': 6265, 'dimensionality': 6266, 'multidimensional': 6267, 'weekly': 6268, 'concrete': 6269, 'implementation': 6270, 'classification': 6271, 'consist': 6272, 'pixels': 6273, 'c0': 6274, 'c9': 6275, 'p256': 6276, 'twoi': 6277, 'release': 6278, 'testing': 6279, 'pixel': 6280, 'implementing': 6281, 'experiments': 6282, 'intputs': 6283, '16x16': 6284, 'anon': 6285, 'verbatim': 6286, 'accomplishing': 6287, 'workaround': 6288, 'surprising': 6289, 'downloading': 6290, 'manner': 6291, '9c': 6292, 'regularizer': 6293, 'discusses': 6294, 'via': 6295, 'confound': 6296, 'accomplish': 6297, 'goal': 6298, 'benefit': 6299, 'intention': 6300, 'penalizing': 6301, 'regime': 6302, 'generalize': 6303, 'successfully': 6304, 'generalizing': 6305, 'classifier': 6306, 'lloyd': 6307, 'mu': 6308, 'var': 6309, '153': 6310, '155': 6311, 'mozilla': 6312, 'chrome': 6313, '1271': 6314, 'safari': 6315, '537': 6316, '10a': 6317, 'correlation': 6318, 'vanish': 6319, 'rescales': 6320, 'charlie': 6321, 'distribute': 6322, 'linearly': 6323, 'linearity': 6324, 'centered': 6325, 'thousand': 6326, 'exceeds': 6327, '84': 6328, '67': 6329, 'responded': 6330, 'uncorrelated': 6331, 'requested': 6332, 'daniel': 6333, 'converges': 6334, 'thx': 6335, 'minimize': 6336, 'influential': 6337, 'clarified': 6338, 'wide': 6339, 'dictionary': 6340, 'clarifies': 6341, 'simplified': 6342, 'cardinality': 6343, 'holdover': 6344, \"algorithm's\": 6345, '984': 6346, 'absolute': 6347, 'extrema': 6348, 'remainder': 6349, 'complexity': 6350, 'worry': 6351, 'backpropagate': 6352, 'derivatives': 6353, 'lenet': 6354, 'convex': 6355, 'convincing': 6356, 'hp': 6357, 'freeze': 6358, 'optimize': 6359, \"can'y\": 6360, \"'finding\": 6361, 'minimums': 6362, 'loops': 6363, 'wow': 6364, 'admittedly': 6365, 'scalable': 6366, 'possibilites': 6367, 'failing': 6368, 'danya': 6369, 'config': 6370, 'triangles': 6371, 'approaching': 6372, 'combination': 6373, 'translated': 6374, 'scaled': 6375, 'identifying': 6376, 'lookout': 6377, 'variants': 6378, 'kevin': 6379, 'equivariance': 6380, 'collinear': 6381, 'sides': 6382, 'arrhenius': 6383, \"\\xa0don't\": 6384, 'shelli': 6385, 'obtain': 6386, 'lessen': 6387, 'define': 6388, 'from\\xa0': 6389, 'calc': 6390, 'denoted': 6391, '\\x94s': 6392, '\\x94t': 6393, 'furthermore': 6394, \"''kinetics\": 6395, \"2''\": 6396, 'hopefully': 6397, 'enjoying': 6398, '0182': 6399, '182': 6400, 'disassociation': 6401, 'ignite': 6402, 'controversy': 6403, 'greatly': 6404, 'sadly': 6405, 'keeps': 6406, 'refresher': 6407, 'chemicals': 6408, 'molarity': 6409, 'numerically': 6410, 'approximate': 6411, 'q2': 6412, 'invert': 6413, 'vary': 6414, '\\xa0use': 6415, 'eqtn': 6416, '0105': 6417, 'n2o4': 6418, '21c': 6419, 'progressed': 6420, '634': 6421, 'kentucky': 6422, '0821': 6423, \"atm's\": 6424, 'tanya': 6425, 'pascals': 6426, '08206': 6427, 'latm': 6428, 'studies': 6429, 'universally': 6430, 'partial': 6431, 'nitrogen': 6432, 'incredible': 6433, 'definitively': 6434, 'celsius': 6435, 'traditionally': 6436, 'chem': 6437, 'cl2': 6438, 'hcl': 6439, '\\xa0am': 6440, 'reversible': 6441, 'cl': 6442, \"'one\": 6443, \"way'\": 6444, 'nbspcn': 6445, 'hcn': 6446, 'idem': 6447, 'formatted': 6448, 'wrongly': 6449, 'lik': 6450, 'unreadable': 6451, 'retry': 6452, 'pdfs': 6453, 'nonspontaneous': 6454, 'thermochemistry': 6455, 'collisions': 6456, 'part4': 6457, 'downloads': 6458, '000001': 6459, 'the\\xa0obtaining': 6460, 'arrange': 6461, 'coincidence': 6462, 'amber': 6463, 'holding': 6464, 'kinetics\\xa0': 6465, 'problem\\xa0': 6466, 'collision': 6467, '2\\xa0': 6468, 'computed': 6469, 'apoint': 6470, 'intermediate': 6471, '170': 6472, 'kj': 6473, 'sooo': 6474, 'no3': 6475, 'wanna': 6476, 'math0': 6477, '0267': 6478, 'quiry': 6479, 'the\\xa0actual': 6480, 'yielding': 6481, 'the\\xa0negative': 6482, 'negate': 6483, '\\xa0sorry': 6484, 'wordy': 6485, 'shiryl': 6486, 'nh3': 6487, 'proceeds': 6488, 'preference': 6489, 'fraction': 6490, 'print': 6491, 'reactants': 6492, 'disappearance': 6493, 'ahhh': 6494, 'yeppers': 6495, 'lauren': 6496, 'conceptualising': 6497, 'buckled': 6498, 'realised': 6499, 'lay': 6500, 'dynamic': 6501, 'equilibria': 6502, 'piecing': 6503, 'crime': 6504, 'scattered': 6505, 'vastly': 6506, 'rote': 6507, 'facts': 6508, 'solving': 6509, 'continuous': 6510, 'outcomes': 6511, \"that'd\": 6512, 'neglect': 6513, 'unrelated': 6514, 'embedded': 6515, '36704': 6516, '63296': 6517, 'b0': 6518, 'gestage': 6519, 'francis': 6520, 'skewed': 6521, 'retaining': 6522, 'skew': 6523, 'q8': 6524, '3000': 6525, '150': 6526, '250': 6527, '3050': 6528, 'q10': 6529, 'income': 6530, '900': 6531, 'sensible': 6532, 'extremes': 6533, '1000': 6534, 'q19': 6535, 'improves': 6536, 'ratios': 6537, 'improve': 6538, 'improved': 6539, 'explode': 6540, 'hrs': 6541, 'mulling': 6542, 'rereading': 6543, 'arrived': 6544, 'arriving': 6545, 'sate': 6546, '0and': 6547, 'p2': 6548, \"john's\": 6549, 'largest': 6550, 'rachel': 6551, '027': 6552, '243': 6553, '\\x80\\x9ccause\\x80\\x9d': 6554, 'articulated': 6555, 'probable': 6556, 'causality': 6557, 'measured': 6558, 'clarifying': 6559, 'null': 6560, 'troubled': 6561, 'severe': 6562, 'pessimist': 6563, '05': 6564, 'successes': 6565, 'hw2': 6566, 'q17': 6567, 'optimist': 6568, 'tonight': 6569, 'announcements': 6570, 'reminder': 6571, 'edt': 6572, 'joined': 6573, 'storks': 6574, 'babies': 6575, 'born': 6576, 'female': 6577, 'salary': 6578, 'joung': 6579, 'worlds': 6580, 'salaries': 6581, 'grades': 6582, 'marked': 6583, 'dorota': 6584, 'hopes': 6585, 'concur': 6586, '1778': 6587, '562': 6588, 'unwritten': 6589, 'plotted': 6590, 'qq': 6591, 'ordering': 6592, 'soil': 6593, 'analyzing': 6594, 'retook': 6595, 'applaud': 6596, 'retake': 6597, 'pays': 6598, '46': 6599, 'reveal': 6600, 'textbook': 6601, 'strengthen': 6602, 'honors': 6603, 'graduate': 6604, 'majored': 6605, 'biology': 6606, 'scheme': 6607, 'pth': 6608, 'bhr': 6609, 'pipelines': 6610, 'instr\\xa0': 6611, 'rf': 6612, 'exe': 6613, 'assess': 6614, 'executing': 6615, 'finishes': 6616, 'branches': 6617, 'intrusive': 6618, 'saves': 6619, 'coherence': 6620, 'interconnected': 6621, 'mismatch': 6622, 'transactions': 6623, 'px': 6624, 'inform': 6625, 'mechanisms': 6626, 'adverse': 6627, 'bandwidth': 6628, 'broadcasts': 6629, 'implementations': 6630, 'hardware': 6631, 'reloads': 6632, '\\xa0during': 6633, 'stalling': 6634, 'underlying': 6635, 'retrieving': 6636, 'handled': 6637, 'interrupt': 6638, 'committed': 6639, 'mmu': 6640, 'reside': 6641, 'retrieves': 6642, 'retrieved': 6643, 'resume': 6644, 'dma': 6645, 'cacheable': 6646, 'flush': 6647, 'purchased': 6648, 'gpus': 6649, 'multithreading': 6650, 'vram': 6651, 'latencies': 6652, 'switched': 6653, 'stucked': 6654, 'scheduler': 6655, 'utilized': 6656, 'commands': 6657, 'msu': 6658, 'nope': 6659, 'switching': 6660, \"'lanes'\": 6661, \"'threads'\": 6662, 'amp': 6663, \"'work\": 6664, \"items'\": 6665, 'opencl': 6666, \"'wrap'\": 6667, 'wrap': 6668, 'continues': 6669, 'existing': 6670, 'associative': 6671, 'lru': 6672, 'selects': 6673, 'consecutive': 6674, 'ooo': 6675, 'takers': 6676, 'concentrate': 6677, 'sd5': 6678, '37': 6679, 'io3': 6680, 'removed': 6681, 'convenient\\xa0to': 6682, '\\xa0register': 6683, 'writeback': 6684, 'ton': 6685, '\\xa0fine': 6686, '\\xa0but': 6687, 'l6s4': 6688, 'iioi': 6689, '\\xa0look': 6690, '\\xa0instruction': 6691, 'agrees': 6692, 'brevity': 6693, 'appearing': 6694, '\\xa0why': 6695, 'sending': 6696, 'signals': 6697, 'skipping': 6698, 'skip': 6699, '\\xa0note': 6700, 'succeeds': 6701, 'committing': 6702, 'selectively': 6703, 'decoded': 6704, 'underway': 6705, 'y3': 6706, 'combinational': 6707, 'evaluate': 6708, 'evaluated': 6709, 'evaluating': 6710, 'architectures': 6711, '8086': 6712, 'conjunction': 6713, 'circuits': 6714, 'familiar\\xa0with': 6715, 'decoders': 6716, 'microprocessor': 6717, 'caching': 6718, 'reviewing': 6719, 'wd': 6720, 'fed': 6721, 'multiplexer': 6722, 'multiplexing': 6723, 'crucial': 6724, 'enabled': 6725, '\\xa0each': 6726, '\\xa0who': 6727, 'enabling': 6728, 'disabling': 6729, 'writebacks': 6730, 'maintaining': 6731, 'multiplier': 6732, 'idle': 6733, 'sacrifice': 6734, 'dislike': 6735, '\\xa0should': 6736, 'l2s3': 6737, 'initialite': 6738, 'interpreted': 6739, 'relates': 6740, '\\xa0write': 6741, 'pipelining': 6742, 'pipelined': 6743, 'motivating': 6744, 'l6s5': 6745, '\\xa0i\\xa0think': 6746, 'implements': 6747, 'videolecture': 6748, 'intruction': 6749, 'l1s5': 6750, 'accumulator': 6751, 'fallacy': 6752, 'weekend': 6753, 'physically': 6754, 'browsing': 6755, 'memory\\xa0': 6756, 'logically': 6757, 'adds': 6758, 'bottlenecks': 6759, 'accessing': 6760, 'fasten': 6761, 'frequently': 6762, 'operands': 6763, 'demotivate': 6764, 'brush': 6765, 'paced': 6766, \"it'll\": 6767, 'i\\xa0believe': 6768, 'are\\xa0': 6769, \"lego's\": 6770, 'plastic': 6771, 'build\\xa0': 6772, '\\xa0control': 6773, 'engines': 6774, 'immensely': 6775, 'machinery': 6776, 'pll': 6777, 'subset': 6778, 'lump': 6779, 'simplistic': 6780, 'stringed': 6781, 'banks': 6782, 'boost': 6783, 'efficiency': 6784, 'digress': 6785, 'proximity': 6786, 'exploited': 6787, 'spends': 6788, '100th': 6789, 'harddisk': 6790, 'swept': 6791, 'disclaimer': 6792, 'informality': 6793, 'l3': 6794, 'cores': 6795, 'specialized': 6796, 'varieties': 6797, 'piles': 6798, 'storing': 6799, 'temporarily': 6800, 'dinner': 6801, 'secondary': 6802, 'l1': 6803, \"cache's\": 6804, 'arrays': 6805, 'a15': 6806, 'wherein': 6807, 'preloaded': 6808, 'donot': 6809, 'efficient': 6810, 'arch': 6811, 'modifying': 6812, 'protecting': 6813, 'modification': 6814, 'hypothetical': 6815, '\\xa0n': 6816, \"'strong\": 6817, \"'weak\": 6818, \"'t'\": 6819, 'mispredicts': 6820, '\\xa0at': 6821, 'refilled': 6822, '\\xa0\\xa0you': 6823, '\\xa0\\xa0if': 6824, 'esu': 6825, 'slot': 6826, 'transitioned': 6827, 'buses': 6828, 'ddr': 6829, 'controller': 6830, 'primitive': 6831, '\\xa0somewhere': 6832, 'generictest': 6833, '\\xa0could': 6834, 'swap': 6835, 'correction': 6836, 'ooops': 6837, '53': 6838, '62': 6839, 'coded': 6840, 'allocation': 6841, '\\xa0let': 6842, 'combinations': 6843, '8kb': 6844, 'kernel': 6845, '56': 6846, '\\xa0that': 6847, 'translates': 6848, '1024': 6849, \"pte's\": 6850, '8192': 6851, 'constitutes': 6852, 'nicely': 6853, '1k': 6854, 'pointers': 6855, '\\xa0looking': 6856, 'subtracting': 6857, '\\xa0would': 6858, 'mb': 6859, 'ps3': 6860, '4a': 6861, 'november': 6862, 'subj': 6863, 'different\\xa0': 6864, 'forwarding': 6865, 'ps2': 6866, 'y1': 6867, '\\xa0d': 6868, '\\xa0x0': 6869, 'loads': 6870, 'stores': 6871, 'dictate': 6872, 'disregard': 6873, 'phases': 6874, 'queried': 6875, 'cc': 6876, 'scanner': 6877, 'mnemonic': 6878, 'behavioral': 6879, '\\xa0a': 6880, 'lately': 6881, 'r13': 6882, 'r17': 6883, 'r15': 6884, 'sw': 6885, 'r21': 6886, 'arounds': 6887, 'instantly': 6888, 'reorders': 6889, 'correctness': 6890, 'misinterpret': 6891, 'grade': 6892, 'latest': 6893, 'corrections': 6894, '228': 6895, '65536': 6896, '68228': 6897, 'math\\xa0': 6898, 'assigment': 6899, \"lru's\": 6900, '64b': 6901, 'cach': 6902, 'log2': 6903, 'honor': 6904, 'worksheet': 6905, \"'f1\": 6906, \"356n'\": 6907, \"'n1'\": 6908, \"356'\": 6909, 'block1': 6910, 'stumps': 6911, 'hub': 6912, 'roller': 6913, 'urlreficularly': 6914, 'odel': 6915, 'stretched': 6916, 'opposed': 6917, 'rm': 6918, 'clarity': 6919, 'gyration': 6920, 'unstretched': 6921, 'stretches': 6922, 'drum': 6923, 'rolles': 6924, 'displacement': 6925, 'rises': 6926, 'ropes': 6927, 'simplicity': 6928, 'contributes': 6929, '2ft': 6930, 'eithrer': 6931, 'o4': 6932, 'pulled': 6933, '3pi': 6934, '180': 6935, '540': 6936, '360': 6937, 'stafford': 6938, '44': 6939, 'yield': 6940, 'mismatched': 6941, 'apparent': 6942, 'simultaneous': 6943, 'rotating': 6944, 'staffs': 6945, 'recommended': 6946, 'supplemental': 6947, \"point's\": 6948, 'alexey': 6949, 'tha': 6950, 'rectilinear': 6951, 'pont': 6952, 'ivestigated': 6953, 'weel': 6954, 'lambde': 6955, 'insure': 6956, 'rewrite': 6957, 'prefere': 6958, 'quizze': 6959, 'lszl': 6960, 'kocsis': 6961, 'careless': 6962, 'instantaneous': 6963, 'centers': 6964, 'slipped': 6965, 'impulsively': 6966, 'concluded': 6967, 'vel': 6968, 'ab': 6969, 'rad': 6970, 'qouizes': 6971, 'induvidual': 6972, 'eachother': 6973, 'diskussion': 6974, 'meter': 6975, 'parentheses': 6976, 'phones': 6977, 'tablets': 6978, 'recalculating': 6979, 'bg': 6980, 'british': 6981, 'bs': 6982, 'agnostic': 6983, 'slug': 6984, 'constants': 6985, '': 6986, 'math': 6987, '1382': 6988, 'lm': 6989, '35575': 6990, 'navigating': 6991, 'converting': 6992, 'uncommon': 6993, 'suggestion': 6994, 'bother': 6995, 'p3': 6996, 'w2': 6997, 'dsimanek': 6998, 'errorman': 6999, 'conversions': 7000, 'users': 7001, 'neighboring': 7002, 'canada': 7003, 'deference': 7004, 'americans': 7005, 'metrication': 7006, 'academe': 7007, 'accepts': 7008, 'socalled': 7009, 'roads': 7010, 'buildings': 7011, 'plants': 7012, 'firms': 7013, 'resting': 7014, 'lies': 7015, 'frictionless': 7016}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n",
      "Shape of data tensor: (315, 1000)\n",
      "Shape of label tensor: (315, 4)\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "print(labels)\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315,)\n",
      "Preparing embedding matrix.\n",
      "(252, 4)\n"
     ]
    }
   ],
   "source": [
    "label1 = []\n",
    "for entry in labels:\n",
    "    label1.append(np.argmax(entry))\n",
    "print(np.array(label1).shape)\n",
    "label1 =np.array(label1)\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "print(y_train.shape)\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "Train on 252 samples, validate on 63 samples\n",
      "Epoch 1/10\n",
      "252/252 [==============================] - 10s 40ms/step - loss: 1.2307 - acc: 0.4643 - val_loss: 1.0312 - val_acc: 0.6349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radhikanikam/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/radhikanikam/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "252/252 [==============================] - 9s 36ms/step - loss: 1.0050 - acc: 0.5595 - val_loss: 1.0291 - val_acc: 0.6190\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/10\n",
      "252/252 [==============================] - 8s 33ms/step - loss: 0.8854 - acc: 0.6230 - val_loss: 1.0116 - val_acc: 0.6349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/10\n",
      "252/252 [==============================] - 10s 38ms/step - loss: 0.7177 - acc: 0.7381 - val_loss: 1.0109 - val_acc: 0.6508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/10\n",
      "252/252 [==============================] - 10s 41ms/step - loss: 0.5530 - acc: 0.7817 - val_loss: 0.9915 - val_acc: 0.6349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/10\n",
      "252/252 [==============================] - 9s 37ms/step - loss: 0.3832 - acc: 0.8770 - val_loss: 1.3375 - val_acc: 0.6349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/10\n",
      "252/252 [==============================] - 9s 37ms/step - loss: 0.2468 - acc: 0.9087 - val_loss: 1.0048 - val_acc: 0.6508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/10\n",
      "252/252 [==============================] - 8s 33ms/step - loss: 0.2491 - acc: 0.9563 - val_loss: 1.1460 - val_acc: 0.5714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/10\n",
      "252/252 [==============================] - 8s 33ms/step - loss: 0.0676 - acc: 0.9960 - val_loss: 2.6482 - val_acc: 0.4127\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/10\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.1700 - acc: 0.9722 - val_loss: 1.1372 - val_acc: 0.6349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "(array([ 0.775     ,  0.22222222,  0.30769231,  0.        ]), array([ 0.75609756,  0.33333333,  0.33333333,  0.        ]), array([ 0.79487179,  0.16666667,  0.28571429,  0.        ]))\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "print('Training model.')\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "#x = Dense(128,activation='relu')(embedded_sequences)\n",
    "#x = Flatten()(x)\n",
    "preds = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "class Metrics(Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict,average=None)\n",
    "        _val_recall = recall_score(val_targ, val_predict,average=None)\n",
    "        _val_precision = precision_score(val_targ, val_predict,average=None)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        return \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "metrics1 = Metrics()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=12,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val),callbacks=[metrics1])\n",
    "\n",
    "print((metrics1.val_f1s[-1], metrics1.val_precisions[-1], metrics1.val_recalls[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315,)\n",
      "(7017, 300)\n",
      "Predicted: [0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 3, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 1, 2, 0, 3, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 1, 3, 0, 0, 2, 0, 2, 0, 3, 0, 2, 2, 0, 2, 0]\n",
      "Actual: [3, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 3, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1, 2, 1, 0, 3, 2, 0, 0, 3, 0, 0, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0]\n",
      "63\n",
      "Accuracy: 0.492063492063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = {\n",
    "    0: 1.,\n",
    "    1: 1.,\n",
    "    2: 5.,\n",
    "    3: 5.\n",
    "}\n",
    "\n",
    "label1 = []\n",
    "for entry in labels:\n",
    "    label1.append(np.argmax(entry))\n",
    "print(np.array(label1).shape)\n",
    "label1 =np.array(label1)\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = label1[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = label1[-num_validation_samples:]\n",
    "\n",
    "#Linear SVM with Glove \n",
    "print(embedding_matrix.shape)\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(class_weight=class_weights)\n",
    "\n",
    "#labels = np.array(labels)\n",
    "#print(y_train.shape)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "predicted = clf.predict(x_val)\n",
    "print(\"Predicted: \"+ str(predicted.tolist()))\n",
    "print(\"Actual: \" + str(y_val.tolist()))\n",
    "print(len(y_val.tolist()))\n",
    "print(\"Accuracy: \"+ str(np.mean(predicted == y_val))+ \"\\n\")\n",
    "#indices = (np.argsort(clf.named_steps['clf'].coef_,axis=1))\n",
    "#print(indices)\n",
    "#features = (clf.named_steps['tfidf'].get_feature_names())\n",
    "# for i in indices:\n",
    "#     print(\"---\"+ str(categories[np.where(np.all(indices==i,axis=1))[0][0]]) + \"---\")\n",
    "#     for j in i[-15:]:\n",
    "#         print(features[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  4  7  4]\n",
      " [ 3  1  2  0]\n",
      " [ 8  0  6  0]\n",
      " [ 2  0  2  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.62      0.63        39\n",
      "          1       0.20      0.17      0.18         6\n",
      "          2       0.35      0.43      0.39        14\n",
      "          3       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.50      0.49      0.49        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_val, predicted))\n",
    "print(metrics.classification_report(y_val, predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
